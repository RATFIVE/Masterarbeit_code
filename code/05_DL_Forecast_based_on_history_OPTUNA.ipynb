{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5543ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gxfs_home/geomar/smomw693/Documents/GEOMAR-DeepLearning/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Interpolating pressure_msl: 100%|██████████| 20184/20184 [00:17<00:00, 1147.61it/s]\n",
      "Interpolating surface_pressure: 100%|██████████| 20184/20184 [00:03<00:00, 5748.01it/s]\n",
      "Interpolating wind_gusts_10m: 100%|██████████| 20184/20184 [00:03<00:00, 5380.47it/s]\n",
      "Interpolating wind_u: 100%|██████████| 20184/20184 [00:04<00:00, 4880.88it/s]\n",
      "Interpolating wind_v: 100%|██████████| 20184/20184 [00:03<00:00, 5616.44it/s]\n",
      "100%|██████████| 20161/20161 [00:02<00:00, 9675.04it/s] \n",
      "100%|██████████| 20161/20161 [00:02<00:00, 7782.17it/s]\n",
      "100%|██████████| 20161/20161 [00:02<00:00, 9721.43it/s]\n",
      "100%|██████████| 20161/20161 [00:02<00:00, 8924.91it/s]\n",
      "100%|██████████| 20161/20161 [00:02<00:00, 9646.13it/s] \n",
      "100%|██████████| 20161/20161 [00:02<00:00, 7541.12it/s]\n",
      "100%|██████████| 20161/20161 [00:02<00:00, 9773.60it/s] \n",
      "100%|██████████| 20161/20161 [00:02<00:00, 7331.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# ## Import Libraries\n",
    "\n",
    "# Standard Libraries\n",
    "import warnings\n",
    "\n",
    "# Scientific Libraries\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error, recall_score\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Torch Tools\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Custom Utilities\n",
    "from utils.dl_helper_functions import (\n",
    "    convert_to_tensors,\n",
    "    create_sequences,\n",
    "    load_picture_lagged_data,\n",
    "    scale_data,\n",
    ")\n",
    "from utils.Model_ConvLSTM import CNNLSTMWaterLevelModel\n",
    "from utils.Model_Training import training_ConvLSTM\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "# Display all columns in pandas\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# TensorBoard writer\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# Define global constants\n",
    "DTYPE_NUMPY = np.float32              # Datentyp für numpy Arrays\n",
    "n_jobs = -1                           # Anzahl CPUs für parallele Prozesse\n",
    "HORIZON = 24 * 3                      # 3 Tage Vorhersagehorizont\n",
    "INITIAL_TRAINING_SIZE = 24 * 183     # 6 Monate Trainingsdaten (4392 Stunden)\n",
    "SEQUENCE_LENGTH = 24                 # 1 Tag als Input-Sequenz\n",
    "\n",
    "# Load data\n",
    "X, y_lagged, y, common_time = load_picture_lagged_data(\n",
    "    return_common_time=True,\n",
    "    verbose=False,\n",
    "    grid_size=25,\n",
    "    n_jobs=n_jobs,\n",
    "    dtype=DTYPE_NUMPY,\n",
    "    pca=False\n",
    ")\n",
    "\n",
    "# Daten vorbereiten\n",
    "X = X.astype(DTYPE_NUMPY)\n",
    "y_lagged = y_lagged.astype(DTYPE_NUMPY)\n",
    "y = y.astype(DTYPE_NUMPY)\n",
    "\n",
    "# Cross-Validation Zeitpunkte\n",
    "folds = {\n",
    "    \"Surge1\": pd.Timestamp(\"2023-02-25 16:00:00\"),\n",
    "    \"Surge2\": pd.Timestamp(\"2023-04-01 09:00:00\"),\n",
    "    \"Surge3\": pd.Timestamp(\"2023-10-07 20:00:00\"),\n",
    "    \"Surge4\": pd.Timestamp(\"2023-10-20 21:00:00\"),\n",
    "    \"Surge5\": pd.Timestamp(\"2024-01-03 01:00:00\"),\n",
    "    \"Surge6\": pd.Timestamp(\"2024-02-09 15:00:00\"),\n",
    "    \"Surge7\": pd.Timestamp(\"2024-12-09 10:00:00\"),\n",
    "    \"normal1\": pd.Timestamp(\"2023-07-01 14:00:00\"),\n",
    "    \"normal2\": pd.Timestamp(\"2024-04-01 18:00:00\"),\n",
    "    \"normal3\": pd.Timestamp(\"2025-01-01 12:00:00\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2124b4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-05 21:36:08,746] A new study created in memory with name: CNNLSTM_Wasserpegel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 1 | Train Loss: 0.0782, Validation Loss: 0.1117 | Train MSE: 0.0687, Val MSE: 0.1117 |\n",
      "| Epoch 2 | Train Loss: 0.0686, Validation Loss: 0.1105 | Train MSE: 0.0686, Val MSE: 0.1105 |\n",
      "| Epoch 3 | Train Loss: 0.0687, Validation Loss: 0.1087 | Train MSE: 0.0873, Val MSE: 0.1087 |\n",
      "| Epoch 4 | Train Loss: 0.0698, Validation Loss: 0.1089 | Train MSE: 0.0687, Val MSE: 0.1089 |\n",
      "| Epoch 5 | Train Loss: 0.0687, Validation Loss: 0.1091 | Train MSE: 0.0686, Val MSE: 0.1091 |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def custom_score(y_true=None, y_pred=None, bins=[1, 2.00], alpha=0.7):\n",
    "    \n",
    "    # Initialisiere Recall- und MSE-Werte\n",
    "    recalls = []\n",
    "    for i in range(y_true.shape[1]):  # Iteriere über jede Spalte\n",
    "        y_true_class = np.digitize(y_true[:, i], bins=bins)\n",
    "        y_pred_class = np.digitize(y_pred[:, i], bins=bins)\n",
    "        recalls.append(recall_score(y_true_class, y_pred_class, average=\"macro\"))\n",
    "    \n",
    "    mean_recall = np.mean(recalls)  # Durchschnittlicher Recall\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return alpha * (1 - mean_recall) + (1 - alpha) * mse\n",
    "\n",
    "def cross_validation_loop(model_name, folds, X, y_lagged, y, common_time, time_delta, trial_params):\n",
    "    fold_results = []\n",
    "\n",
    "    for surge_name, fold in folds.items():\n",
    "        start_cutoff = fold - time_delta\n",
    "        end_cutoff = fold + time_delta\n",
    "        idx_start_cutoff = np.where(common_time == start_cutoff)[0][0]\n",
    "        idx_end_cutoff = np.where(common_time == end_cutoff)[0][0]\n",
    "\n",
    "        X_test = X[idx_start_cutoff:idx_end_cutoff]\n",
    "        y_lagged_test = y_lagged[idx_start_cutoff:idx_end_cutoff]\n",
    "        y_test = y[idx_start_cutoff:idx_end_cutoff]\n",
    "\n",
    "        X_train = X.copy()\n",
    "        y_lagged_train = y_lagged.copy()\n",
    "        y_train = y.copy()\n",
    "        X_train[idx_start_cutoff:idx_end_cutoff] = np.nan\n",
    "        y_lagged_train[idx_start_cutoff:idx_end_cutoff] = np.nan\n",
    "        y_train[idx_start_cutoff:idx_end_cutoff] = np.nan\n",
    "\n",
    "        X_train, y_lagged_train, y_train = create_sequences(X_train, y_lagged_train, y_train, SEQUENCE_LENGTH, HORIZON)\n",
    "        X_test, y_lagged_test, y_test = create_sequences(X_test, y_lagged_test, y_test, SEQUENCE_LENGTH, HORIZON)\n",
    "\n",
    "        gap = 168\n",
    "        X_test = X_test[gap:-gap]\n",
    "        y_lagged_test = y_lagged_test[gap:-gap]\n",
    "        y_test = y_test[gap:-gap]\n",
    "\n",
    "        scaler_X = StandardScaler()\n",
    "        scaler_y = StandardScaler()\n",
    "        X_train, y_lagged_train, y_train, _, _, _, X_test, y_lagged_test, y_test = scale_data(\n",
    "            X_scaler=scaler_X, y_lagged_scaler=scaler_y,\n",
    "            X_train=X_train, y_lagged_train=y_lagged_train, y_train=y_train,\n",
    "            X_val=None, y_lagged_val=None, y_val=None,\n",
    "            X_test=X_test, y_lagged_test=y_lagged_test, y_test=y_test,\n",
    "            dtype=DTYPE_NUMPY, verbose=False\n",
    "        )\n",
    "\n",
    "        X_train_tensor, y_lagged_train_tensor, y_train_tensor, _, _, _, X_test_tensor, y_lagged_test_tensor, y_test_tensor = convert_to_tensors(\n",
    "            X_train=X_train, y_lagged_train=y_lagged_train, y_train=y_train,\n",
    "            X_val=None, y_lagged_val=None, y_val=None,\n",
    "            X_test=X_test, y_lagged_test=y_lagged_test, y_test=y_test,\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        model = CNNLSTMWaterLevelModel(\n",
    "            in_channels=X_train_tensor.shape[2],\n",
    "            forecast_horizon=HORIZON,\n",
    "            lagged_input_dim=y_lagged_train_tensor.shape[2],\n",
    "            H=X_train_tensor.shape[3],\n",
    "            W=X_train_tensor.shape[4],\n",
    "            cnn1_out_channels=trial_params[\"cnn1_out_channels\"],\n",
    "            cnn2_out_channels=trial_params[\"cnn2_out_channels\"],\n",
    "            cnn1_kernel_size=3,\n",
    "            cnn1_padding=1,\n",
    "            cnn2_kernel_size=3,\n",
    "            cnn2_padding=1,\n",
    "            cnn_linear_out_features=trial_params[\"cnn_linear_out_features\"],\n",
    "            lstm_hidden_dim=trial_params[\"lstm_hidden_dim\"],\n",
    "            lstm_layers=trial_params[\"lstm_layers\"],\n",
    "            lstm_input_size=trial_params[\"cnn_linear_out_features\"],\n",
    "            dropout=trial_params[\"dropout\"]\n",
    "        )\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=trial_params[\"lr\"])\n",
    "\n",
    "        best_model = training_ConvLSTM(\n",
    "            model,\n",
    "            X_train=X_train_tensor,\n",
    "            y_train=y_train_tensor,\n",
    "            X_val=X_test_tensor,\n",
    "            y_val=y_test_tensor,\n",
    "            y_lagged_train=y_lagged_train_tensor,\n",
    "            y_lagged_val=y_lagged_test_tensor,\n",
    "            epochs=trial_params[\"epochs\"],\n",
    "            batch_size=128,\n",
    "            optimizer=optimizer,\n",
    "            writer=None,\n",
    "            verbose=True,\n",
    "            log_tensorboard=False\n",
    "        )\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = model.predict(X_test_tensor, y_lagged_test_tensor).cpu().numpy()\n",
    "            y_true = y_test_tensor.cpu().numpy()\n",
    "\n",
    "        score = custom_score(y_true=y_true, y_pred=y_pred, bins=[1, 2.00], alpha=0.7)\n",
    "        fold_results.append(score)\n",
    "\n",
    "    return fold_results\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    trial_params = {\n",
    "        \"cnn1_out_channels\": trial.suggest_categorical(\"cnn1_out_channels\", [16, 32, 64]),\n",
    "        \"cnn2_out_channels\": trial.suggest_categorical(\"cnn2_out_channels\", [32, 64, 128]),\n",
    "        \"cnn_linear_out_features\": trial.suggest_categorical(\"cnn_linear_out_features\", [64, 128, 256]),\n",
    "        \"lstm_hidden_dim\": trial.suggest_categorical(\"lstm_hidden_dim\", [32, 64, 128]),\n",
    "        \"lstm_layers\": trial.suggest_int(\"lstm_layers\", 1, 3),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.6),\n",
    "        \"lr\": trial.suggest_float(\"lr\", 0.0001, 0.1, log=True),\n",
    "        \"epochs\": 10,\n",
    "    }\n",
    "\n",
    "    scores = cross_validation_loop(\n",
    "        model_name=\"ConvLSTM\",\n",
    "        folds=folds,\n",
    "        X=X.astype(DTYPE_NUMPY),\n",
    "        y_lagged=y_lagged.astype(DTYPE_NUMPY),\n",
    "        y=y.astype(DTYPE_NUMPY),\n",
    "        common_time=common_time,\n",
    "        time_delta=pd.Timedelta(hours=168 * 4),\n",
    "        trial_params=trial_params\n",
    "    )\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=\"CNNLSTM_Wasserpegel\")\n",
    "study.optimize(objective, n_trials=30)  # z. B. 30 Versuche oder 1 Stunde max\n",
    "\n",
    "print(\"Beste Parameter:\", study.best_params)\n",
    "print(\"Bester Score:\", study.best_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
