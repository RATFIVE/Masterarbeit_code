{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fragen\n",
        "\n",
        "1. Analyse Allgemein\n",
        "    - Lässt sich ein Zusammenhang zwischen dem Wasserpegel von den Beobachtungsdaten und den Modelldaten erkennen?\n",
        "    - Wie ist die Korrelation zwischen Wasserpegel Model und Wasserpegel Beobachtung\n",
        "\n",
        "2. Analyse Sturmfluten\n",
        "    - Wie verhält sich Wind, Windrichtung bei den unterschiedlichen Sturmfluten\n",
        "    - Wie vehält sich Wassergeschwindigkeit, Richtung bei den unterschiedlichen Sturmfluten\n",
        "    - Lassen sich Korrelationen zwischen den Features und dem Wasserpegel (sla) erkennen? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpOApovX9ZhU"
      },
      "source": [
        "## Import Libaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1E2fH33dHzxc"
      },
      "outputs": [],
      "source": [
        "# import all necessary libraries\n",
        "import os\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "import cartopy.feature as cfeature\n",
        "import geodatasets\n",
        "import geopandas as gpd\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shapely.geometry\n",
        "import xarray as xr\n",
        "from joblib import Parallel, delayed\n",
        "from mpl_toolkits.basemap import Basemap\n",
        "from scipy.interpolate import griddata\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "from tqdm import tqdm\n",
        "from utils.eda_helper_functions import (\n",
        "    check_missing_times,\n",
        "    group_data_hourly,\n",
        "    load_insitu_data,\n",
        "    load_ocean_data,\n",
        "    load_weather_data,\n",
        "    plot_water_level_anomalies,\n",
        "    process_df,\n",
        "    process_flensburg_data,\n",
        "    show_df,\n",
        ")\n",
        "\n",
        "# Ignore SettingWithCopyWarning:\n",
        "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
        "\n",
        "# Display all columns\n",
        "pd.options.display.max_columns = None\n",
        "\n",
        "\n",
        "# Global variables\n",
        "# Define the grid size of the ocean and weather data\n",
        "OCEAN_POINTS = 30\n",
        "WEATHER_POINTS = 10\n",
        "\n",
        "LAT_FLENSBURG = 54.796001\n",
        "LON_FLENSBURG = 9.436999\n",
        "\n",
        "# Definition of the ocean data dictionary\n",
        "OCEAN_DICT = {\n",
        "    \"bottomT\": {\n",
        "        \"unit\": \"°C\",\n",
        "        \"description\": \"Sea water potential temperature at sea floor\",\n",
        "        \"explanation\": \"Temperature of seawater at the ocean floor, accounting for pressure effects.\"\n",
        "    },\n",
        "    \"mlotst\": {\n",
        "        \"unit\": \"m\",\n",
        "        \"description\": \"Ocean mixed layer thickness defined by sigma theta\",\n",
        "        \"explanation\": \"Depth of the ocean's surface layer where temperature and salinity are relatively uniform.\"\n",
        "    },\n",
        "    \"siconc\": {\n",
        "        \"unit\": \"-\",\n",
        "        \"description\": \"Sea ice area fraction\",\n",
        "        \"explanation\": \"Fractional coverage of sea ice in a given area (0 = no ice, 1 = full coverage).\"\n",
        "    },\n",
        "    \"sithick\": {\n",
        "        \"unit\": \"m\",\n",
        "        \"description\": \"Sea ice thickness\",\n",
        "        \"explanation\": \"Thickness of sea ice from surface to bottom.\"\n",
        "    },\n",
        "    \"sla\": {\n",
        "        \"unit\": \"m\",\n",
        "        \"description\": \"Sea surface height above sea level\",\n",
        "        \"explanation\": \"Deviation of the ocean surface from the mean sea level, can indicate currents or tides.\"\n",
        "    },\n",
        "    \"so\": {\n",
        "        \"unit\": \"$1 / 10^3$\",\n",
        "        \"description\": \"Sea water salinity\",\n",
        "        \"explanation\": \"Salinity of seawater (measured dimensionless, typically expressed in parts per thousand or PSU).\"\n",
        "    },\n",
        "    \"sob\": {\n",
        "        \"unit\": \"$1 / 10^3$\",\n",
        "        \"description\": \"Sea water salinity at sea floor\",\n",
        "        \"explanation\": \"Salinity of seawater at the ocean floor, normalized (0.001 units).\"\n",
        "    },\n",
        "    \"thetao\": {\n",
        "        \"unit\": \"°C\",\n",
        "        \"description\": \"Sea water potential temperature\",\n",
        "        \"explanation\": \"Potential temperature of seawater, referenced to sea surface pressure.\"\n",
        "    },\n",
        "    \"uo\": {\n",
        "        \"unit\": \"m/s\",\n",
        "        \"description\": \"Eastward sea water velocity\",\n",
        "        \"explanation\": \"Velocity component of seawater flow towards the east.\"\n",
        "    },\n",
        "    \"vo\": {\n",
        "        \"unit\": \"m/s\",\n",
        "        \"description\": \"Northward sea water velocity\",\n",
        "        \"explanation\": \"Velocity component of seawater flow towards the north.\"\n",
        "    },\n",
        "    \"wo\": {\n",
        "        \"unit\": \"m/s\",\n",
        "        \"description\": \"Upward sea water velocity\",\n",
        "        \"explanation\": \"Vertical velocity of seawater, positive upward.\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Definition of the weather data dictionary\n",
        "WEATHER_DICT = {\n",
        "    \"temperature_2m\": {\n",
        "        \"unit\": \"°C\",\n",
        "        \"description\": \"Temperature (2 m)\",\n",
        "        \"explanation\": \"Air temperature at 2 meters above ground.\"\n",
        "    },\n",
        "    \"relative_humidity_2m\": {\n",
        "        \"unit\": \"%\",\n",
        "        \"description\": \"Relative Humidity (2 m)\",\n",
        "        \"explanation\": \"Percentage of humidity at 2 meters height.\"\n",
        "    },\n",
        "    \"dew_point_2m\": {\n",
        "        \"unit\": \"°C\",\n",
        "        \"description\": \"Dewpoint (2 m)\",\n",
        "        \"explanation\": \"Temperature at which air moisture condenses (dew point) at 2 meters height.\"\n",
        "    },\n",
        "    \"apparent_temperature\": {\n",
        "        \"unit\": \"°C\",\n",
        "        \"description\": \"Apparent Temperature\",\n",
        "        \"explanation\": \"Perceived temperature considering wind and humidity.\"\n",
        "    },\n",
        "    \"precipitation_probability\": {\n",
        "        \"unit\": \"%\",\n",
        "        \"description\": \"Precipitation Probability\",\n",
        "        \"explanation\": \"Probability of precipitation.\"\n",
        "    },\n",
        "    \"precipitation\": {\n",
        "        \"unit\": \"mm\",\n",
        "        \"description\": \"Precipitation (rain + showers + snow)\",\n",
        "        \"explanation\": \"Total precipitation amount (rain, showers, snow).\"\n",
        "    },\n",
        "    \"rain\": {\n",
        "        \"unit\": \"mm\",\n",
        "        \"description\": \"Rain\",\n",
        "        \"explanation\": \"Precipitation amount due to rain.\"\n",
        "    },\n",
        "    \"showers\": {\n",
        "        \"unit\": \"mm\",\n",
        "        \"description\": \"Showers\",\n",
        "        \"explanation\": \"Precipitation amount due to showers.\"\n",
        "    },\n",
        "    \"snowfall\": {\n",
        "        \"unit\": \"cm\",\n",
        "        \"description\": \"Snowfall\",\n",
        "        \"explanation\": \"Precipitation amount due to snow.\"\n",
        "    },\n",
        "    \"snow_depth\": {\n",
        "        \"unit\": \"cm\",\n",
        "        \"description\": \"Snow Depth\",\n",
        "        \"explanation\": \"Total snow depth on the ground.\"\n",
        "    },\n",
        "    \"weather_code\": {\n",
        "        \"unit\": \"-\",\n",
        "        \"description\": \"Weather code\",\n",
        "        \"explanation\": \"Classification of weather conditions by a code (e.g., sunny, cloudy).\"\n",
        "    },\n",
        "    \"pressure_msl\": {\n",
        "        \"unit\": \"hPa\",\n",
        "        \"description\": \"Sealevel Pressure\",\n",
        "        \"explanation\": \"Atmospheric pressure reduced to sea level.\"\n",
        "    },\n",
        "    \"surface_pressure\": {\n",
        "        \"unit\": \"hPa\",\n",
        "        \"description\": \"Surface Pressure\",\n",
        "        \"explanation\": \"Actual atmospheric pressure at the surface.\"\n",
        "    },\n",
        "    \"cloud_cover\": {\n",
        "        \"unit\": \"%\",\n",
        "        \"description\": \"Cloud cover Total\",\n",
        "        \"explanation\": \"Total cloud coverage.\"\n",
        "    },\n",
        "    \"cloud_cover_low\": {\n",
        "        \"unit\": \"%\",\n",
        "        \"description\": \"Cloud cover Low\",\n",
        "        \"explanation\": \"Cloud coverage by low-level clouds.\"\n",
        "    },\n",
        "    \"cloud_cover_mid\": {\n",
        "        \"unit\": \"%\",\n",
        "        \"description\": \"Cloud cover Mid\",\n",
        "        \"explanation\": \"Cloud coverage by mid-level clouds.\"\n",
        "    },\n",
        "    \"cloud_cover_high\": {\n",
        "        \"unit\": \"%\",\n",
        "        \"description\": \"Cloud cover High\",\n",
        "        \"explanation\": \"Cloud coverage by high-level clouds.\"\n",
        "    },\n",
        "    \"visibility\": {\n",
        "        \"unit\": \"m\",\n",
        "        \"description\": \"Visibility\",\n",
        "        \"explanation\": \"Visibility distance.\"\n",
        "    },\n",
        "    \"evapotranspiration\": {\n",
        "        \"unit\": \"mm\",\n",
        "        \"description\": \"Evapotranspiration\",\n",
        "        \"explanation\": \"Water loss through evaporation and plant transpiration.\"\n",
        "    },\n",
        "    \"et0_fao_evapotranspiration\": {\n",
        "        \"unit\": \"mm\",\n",
        "        \"description\": \"Reference Evapotranspiration (ET₀)\",\n",
        "        \"explanation\": \"Standardized reference evapotranspiration according to FAO.\"\n",
        "    },\n",
        "    \"vapour_pressure_deficit\": {\n",
        "        \"unit\": \"hPa\",\n",
        "        \"description\": \"Vapour Pressure Deficit\",\n",
        "        \"explanation\": \"Difference between saturation and actual vapor pressure.\"\n",
        "    },\n",
        "    \"wind_speed_10m\": {\n",
        "        \"unit\": \"km/h\",\n",
        "        \"description\": \"Wind Speed (10 m)\",\n",
        "        \"explanation\": \"Wind speed at 10 meters above ground.\"\n",
        "    },\n",
        "    \"wind_speed_80m\": {\n",
        "        \"unit\": \"km/h\",\n",
        "        \"description\": \"Wind Speed (80 m)\",\n",
        "        \"explanation\": \"Wind speed at 80 meters above ground.\"\n",
        "    },\n",
        "    \"wind_speed_120m\": {\n",
        "        \"unit\": \"km/h\",\n",
        "        \"description\": \"Wind Speed (120 m)\",\n",
        "        \"explanation\": \"Wind speed at 120 meters above ground.\"\n",
        "    },\n",
        "    \"wind_speed_180m\": {\n",
        "        \"unit\": \"km/h\",\n",
        "        \"description\": \"Wind Speed (180 m)\",\n",
        "        \"explanation\": \"Wind speed at 180 meters above ground.\"\n",
        "    },\n",
        "    \"wind_direction_10m\": {\n",
        "        \"unit\": \"°\",\n",
        "        \"description\": \"Wind Direction (10 m)\",\n",
        "        \"explanation\": \"Wind direction in degrees at 10 meters height (0° = North).\"\n",
        "    },\n",
        "    \"wind_direction_80m\": {\n",
        "        \"unit\": \"°\",\n",
        "        \"description\": \"Wind Direction (80 m)\",\n",
        "        \"explanation\": \"Wind direction in degrees at 80 meters height.\"\n",
        "    },\n",
        "    \"wind_direction_120m\": {\n",
        "        \"unit\": \"°\",\n",
        "        \"description\": \"Wind Direction (120 m)\",\n",
        "        \"explanation\": \"Wind direction in degrees at 120 meters height.\"\n",
        "    },\n",
        "    \"wind_direction_180m\": {\n",
        "        \"unit\": \"°\",\n",
        "        \"description\": \"Wind Direction (180 m)\",\n",
        "        \"explanation\": \"Wind direction in degrees at 180 meters height.\"\n",
        "    },\n",
        "    \"wind_gusts_10m\": {\n",
        "        \"unit\": \"km/h\",\n",
        "        \"description\": \"Wind Gusts (10 m)\",\n",
        "        \"explanation\": \"Maximum gust wind speed at 10 meters height.\"\n",
        "    },\n",
        "    \"temperature_80m\": {\n",
        "        \"unit\": \"°C\",\n",
        "        \"description\": \"Temperature (80 m)\",\n",
        "        \"explanation\": \"Air temperature at 80 meters above ground.\"\n",
        "    },\n",
        "    \"temperature_120m\": {\n",
        "        \"unit\": \"°C\",\n",
        "        \"description\": \"Temperature (120 m)\",\n",
        "        \"explanation\": \"Air temperature at 120 meters above ground.\"\n",
        "    },\n",
        "    \"temperature_180m\": {\n",
        "        \"unit\": \"°C\",\n",
        "        \"description\": \"Temperature (180 m)\",\n",
        "        \"explanation\": \"Air temperature at 180 meters above ground.\"\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "ocean_data_path = Path(f\"../data/numerical_data/points{OCEAN_POINTS}\")\n",
        "print(ocean_data_path)\n",
        "weather_data_path = Path(f\"../data/numerical_data/points{WEATHER_POINTS}\")\n",
        "print(weather_data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load The Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ocean Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Feature | Unit | Description | Explanation |\n",
        "|:---|:---|:---|:---|\n",
        "| bottomT | °C | Sea water potential temperature at sea floor | Temperature of seawater at the ocean floor, accounting for pressure effects. |\n",
        "| mlotst | m | Ocean mixed layer thickness defined by sigma theta | Depth of the ocean's surface layer where temperature and salinity are relatively uniform. |\n",
        "| siconc | - | Sea ice area fraction | Fractional coverage of sea ice in a given area (0 = no ice, 1 = full coverage). |\n",
        "| sithick | m | Sea ice thickness | Thickness of sea ice from surface to bottom. |\n",
        "| sla | m | Sea surface height above sea level | Deviation of the ocean surface from the mean sea level, can indicate currents or tides. |\n",
        "| so | $1 / 10^3$ | Sea water salinity | Salinity of seawater (measured dimensionless, typically expressed in parts per thousand or PSU). |\n",
        "| sob | $1 / 10^3$| Sea water salinity at sea floor | Salinity of seawater at the ocean floor, normalized (0.001 units). |\n",
        "| thetao | °C | Sea water potential temperature | Potential temperature of seawater, referenced to sea surface pressure. |\n",
        "| uo | m/s | Eastward sea water velocity | Velocity component of seawater flow towards the east. |\n",
        "| vo | m/s | Northward sea water velocity | Velocity component of seawater flow towards the north. |\n",
        "| wo | m/s | Upward sea water velocity | Vertical velocity of seawater, positive upward. |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ocean = load_ocean_data(ocean_data_path, OCEAN_POINTS, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ocean = process_df(df_ocean, drop_cols=[\"depth\"], verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Weather Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Feature | Unit | Description | Explanation |\n",
        "|:---|:---|:---|:---|\n",
        "| temperature_2m | °C | Temperature (2 m) | Air temperature at 2 meters above ground. |\n",
        "| relative_humidity_2m | % | Relative Humidity (2 m) | Percentage of humidity at 2 meters height. |\n",
        "| dew_point_2m | °C | Dewpoint (2 m) | Temperature at which air moisture condenses (dew point) at 2 meters height. |\n",
        "| apparent_temperature | °C | Apparent Temperature | Perceived temperature considering wind and humidity. |\n",
        "| precipitation_probability | % | Precipitation Probability | Probability of precipitation. |\n",
        "| precipitation | mm | Precipitation (rain + showers + snow) | Total precipitation amount (rain, showers, snow). |\n",
        "| rain | mm | Rain | Precipitation amount due to rain. |\n",
        "| showers | mm | Showers | Precipitation amount due to showers. |\n",
        "| snowfall | cm | Snowfall | Precipitation amount due to snow. |\n",
        "| snow_depth | cm | Snow Depth | Total snow depth on the ground. |\n",
        "| weather_code | - | Weather code | Classification of weather conditions by a code (e.g., sunny, cloudy). |\n",
        "| pressure_msl | hPa | Sealevel Pressure | Atmospheric pressure reduced to sea level. |\n",
        "| surface_pressure | hPa | Surface Pressure | Actual atmospheric pressure at the surface. |\n",
        "| cloud_cover | % | Cloud cover Total | Total cloud coverage. |\n",
        "| cloud_cover_low | % | Cloud cover Low | Cloud coverage by low-level clouds. |\n",
        "| cloud_cover_mid | % | Cloud cover Mid | Cloud coverage by mid-level clouds. |\n",
        "| cloud_cover_high | % | Cloud cover High | Cloud coverage by high-level clouds. |\n",
        "| visibility | m | Visibility | Visibility distance. |\n",
        "| evapotranspiration | mm | Evapotranspiration | Water loss through evaporation and plant transpiration. |\n",
        "| et0_fao_evapotranspiration | mm | Reference Evapotranspiration (ET₀) | Standardized reference evapotranspiration according to FAO. |\n",
        "| vapour_pressure_deficit | hPa | Vapour Pressure Deficit | Difference between saturation and actual vapor pressure. |\n",
        "| wind_speed_10m | km/h | Wind Speed (10 m) | Wind speed at 10 meters above ground. |\n",
        "| wind_speed_80m | km/h | Wind Speed (80 m) | Wind speed at 80 meters above ground. |\n",
        "| wind_speed_120m | km/h | Wind Speed (120 m) | Wind speed at 120 meters above ground. |\n",
        "| wind_speed_180m | km/h | Wind Speed (180 m) | Wind speed at 180 meters above ground. |\n",
        "| wind_direction_10m | ° | Wind Direction (10 m) | Wind direction in degrees at 10 meters height (0° = North). |\n",
        "| wind_direction_80m | ° | Wind Direction (80 m) | Wind direction in degrees at 80 meters height. |\n",
        "| wind_direction_120m | ° | Wind Direction (120 m) | Wind direction in degrees at 120 meters height. |\n",
        "| wind_direction_180m | ° | Wind Direction (180 m) | Wind direction in degrees at 180 meters height. |\n",
        "| wind_gusts_10m | km/h | Wind Gusts (10 m) | Maximum gust wind speed at 10 meters height. |\n",
        "| temperature_80m | °C | Temperature (80 m) | Air temperature at 80 meters above ground. |\n",
        "| temperature_120m | °C | Temperature (120 m) | Air temperature at 120 meters above ground. |\n",
        "| temperature_180m | °C | Temperature (180 m) | Air temperature at 180 meters above ground. |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_weather = load_weather_data(weather_data_path, WEATHER_POINTS, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_weather = process_df(df_weather, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## In Situ Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Feature   | Unit    | Description                     | Explanation                                                                 |\n",
        "|:----------|:--------|:---------------------------------|:---------------------------------------------------------------------------|\n",
        "| time      | -       | Timestamp                        | Date and time of the observation (UTC).                                    |\n",
        "| depth     | m       | Measurement depth                | Depth below sea surface where the measurement was taken.                   |\n",
        "| time_qc   | -       | Time quality control flag        | Quality control indicator for the timestamp (e.g., 1 = good).              |\n",
        "| deph      | m       | Nominal depth                    | Nominal (intended) depth of the measurement, could differ from actual depth.|\n",
        "| latitude  | degrees | Latitude                         | Geographic coordinate specifying north-south position.                     |\n",
        "| longitude | degrees | Longitude                        | Geographic coordinate specifying east-west position.                       |\n",
        "| slev      | m       | Sea level                        | Measured sea surface height relative to a reference Datum |\n",
        "| slev_qc   | -       | Sea level quality control flag   | Quality control indicator for sea level measurement (e.g., 1 = good).       |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.eda_helper_functions import load_insitu_data\n",
        "\n",
        "df_insitu = load_insitu_data(verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.eda_helper_functions import process_flensburg_data\n",
        "\n",
        "df_insitu = process_flensburg_data(df_insitu, \n",
        "                                      start_time=df_ocean['time'].min(),\n",
        "                                      end_time=df_ocean['time'].max(),\n",
        "                                      verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.eda_helper_functions import group_data_hourly\n",
        "\n",
        "df_insitu = group_data_hourly(df_insitu)\n",
        "df_insitu = process_df(df_insitu, drop_cols=[\"deph\"], verbose=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot Flensburg Observation Waterlevel Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.eda_helper_functions import plot_water_level_anomalies\n",
        "\n",
        "fig, ax = plot_water_level_anomalies(df_insitu)\n",
        "plt.show()\n",
        "\n",
        "import datetime\n",
        "\n",
        "sturm_surge_list = [datetime.datetime(2023, 2, 25, 17, 0),\n",
        "                    datetime.datetime(2023, 4, 1, 12, 0),\n",
        "                    datetime.datetime(2023, 10, 7, 20, 0),\n",
        "                    datetime.datetime(2023, 10, 20, 0, 0),\n",
        "                    datetime.datetime(2024, 1, 3, 9, 0),\n",
        "                    datetime.datetime(2024, 2, 9, 18, 0),\n",
        "                    datetime.datetime(2024, 12, 9, 16, 0),\n",
        "                    ]\n",
        "\n",
        "for time in sturm_surge_list:\n",
        "    start_time = time - datetime.timedelta(days=2)\n",
        "    end_time = time + datetime.timedelta(days=2)\n",
        "    df_insitu_sturm = df_insitu[(df_insitu[\"time\"] >= start_time) & (df_insitu[\"time\"] <= end_time)]\n",
        "    plot_water_level_anomalies(df_insitu_sturm, start_date=start_time, end_date=end_time)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display Ocean and Weather Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.eda_helper_functions import plot_coordinates\n",
        "\n",
        "plot_coordinates(df_ocean, df_weather, df_insitu, save_png=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Distributions of the Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.eda_helper_functions import plot_histogram\n",
        "\n",
        "def plot_feature_distribution(df:pd.DataFrame, features:list, bins:int=50, save_png:bool=False):\n",
        "    \"\"\"\n",
        "    Plots the distribution of features in a DataFrame.\n",
        "    \n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing the features.\n",
        "        features (list): List of feature names to plot.\n",
        "        bins (int): Number of bins for the histogram.\n",
        "        save_png (bool): Whether to save the plot as a PNG file.\n",
        "    \"\"\"\n",
        "    n_cols = 3\n",
        "    n_rows = (len(features) + n_cols - 1) // n_cols\n",
        "\n",
        "    fig = plt.figure(figsize=(8 * n_cols, 5 * n_rows))\n",
        "    gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)\n",
        "\n",
        "    fig.suptitle(\"Feature Distribution\", fontsize=20, y=0.98)\n",
        "\n",
        "    for idx, feature in tqdm(enumerate(features), total=len(features), desc=\"Plotting features\"):\n",
        "        #print(f\"Plotting distribution for {feature}\")\n",
        "        ax = fig.add_subplot(gs[idx])\n",
        "        plot_histogram(df, column=feature, bins=bins, ax=ax, show_stats=True)\n",
        "\n",
        "    # Statt tight_layout --> subplots_adjust\n",
        "    fig.subplots_adjust(top=0.92, hspace=0.5, wspace=0.3)  # <-- manuell fein justieren!\n",
        "    if save_png:\n",
        "        plt.savefig(f\"../figures/distribution_{feature}.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_insitu.info())\n",
        "print(df_insitu.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_feature_distribution(df_ocean, df_ocean.columns, bins=50, save_png=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_feature_distribution(df_weather, df_weather.columns, bins=50, save_png=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_feature_distribution(df_insitu, df_insitu.columns, bins=50, save_png=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cluster df_ocean into K = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ocean = load_ocean_data(ocean_data_path, OCEAN_POINTS, verbose=False)\n",
        "df_ocean = process_df(df_ocean, drop_cols=[\"depth\"], verbose=False)\n",
        "\n",
        "df_weather = load_weather_data(weather_data_path, WEATHER_POINTS, verbose=False)\n",
        "df_weather = process_df(df_weather, verbose=False)\n",
        "\n",
        "df_insitu = load_insitu_data(verbose=False)\n",
        "df_insitu = process_flensburg_data(df_insitu, \n",
        "                                      start_time=df_ocean['time'].min(),\n",
        "                                      end_time=df_ocean['time'].max(),\n",
        "                                      verbose=False)\n",
        "\n",
        "df_insitu = group_data_hourly(df_insitu)\n",
        "df_insitu = process_df(df_insitu, drop_cols=[\"deph\"], verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.basemap import Basemap\n",
        "\n",
        "# === 1. Features auswählen (außer Zeit, da KMeans keine Zeit versteht)\n",
        "features = ['latitude', 'longitude', 'sla', ]\n",
        "X = df_ocean[features].dropna()\n",
        "\n",
        "# === 2. Standardisieren\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# === 3. KMeans-Clustering (k=3)\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "clusters = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# === 4. Cluster-Labels zurück ins DataFrame\n",
        "df_clustered = df_ocean.loc[X.index].copy()\n",
        "df_clustered['cluster'] = clusters\n",
        "\n",
        "# === 5. Mittelpunkt berechnen für Basemap\n",
        "mean_lat = df_clustered['latitude'].mean()\n",
        "mean_lon = df_clustered['longitude'].mean()\n",
        "\n",
        "# === 6. Karte mit Basemap zeichnen\n",
        "plt.figure(figsize=(10, 8))\n",
        "m = Basemap(\n",
        "    projection='lcc',\n",
        "    resolution='i',\n",
        "    lat_0=mean_lat,\n",
        "    lon_0=mean_lon,\n",
        "    width=1.2e6,\n",
        "    height=1.2e6,\n",
        ")\n",
        "\n",
        "m.drawcoastlines()\n",
        "m.drawcountries()\n",
        "m.drawmapboundary(fill_color='lightblue')\n",
        "m.fillcontinents(color='beige', lake_color='lightblue')\n",
        "\n",
        "# Farben definieren\n",
        "colors = ['red', 'green', 'blue']\n",
        "\n",
        "# === 7. Punkte plotten\n",
        "for cluster_id in range(3):\n",
        "    cluster_data = df_clustered[df_clustered['cluster'] == cluster_id]\n",
        "    x, y = m(cluster_data['longitude'].values, cluster_data['latitude'].values)\n",
        "    m.scatter(x, y, s=10, c=colors[cluster_id], label=f'Cluster {cluster_id}', alpha=0.6)\n",
        "\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('KMeans Clustering (k=3) der Ozeandaten')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparison of SLEV and SLA\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ocean = load_ocean_data(ocean_data_path, OCEAN_POINTS, verbose=False)\n",
        "df_ocean = process_df(df_ocean, drop_cols=[\"depth\"], verbose=False)\n",
        "\n",
        "df_weather = load_weather_data(weather_data_path, WEATHER_POINTS, verbose=False)\n",
        "df_weather = process_df(df_weather, verbose=False)\n",
        "\n",
        "df_insitu = load_insitu_data(verbose=False)\n",
        "df_insitu = process_flensburg_data(df_insitu, \n",
        "                                      start_time=df_ocean['time'].min(),\n",
        "                                      end_time=df_ocean['time'].max(),\n",
        "                                      verbose=False)\n",
        "\n",
        "df_insitu = group_data_hourly(df_insitu)\n",
        "df_insitu = process_df(df_insitu, drop_cols=[\"deph\"], verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# find the closest location in df_ocean to the target location\n",
        "def find_closest_location(df: pd.DataFrame, target_lat: float, target_lon: float) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Find the closest location in the DataFrame to the target latitude and longitude.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): DataFrame containing the data with 'latitude' and 'longitude'.\n",
        "        target_lat (float): Target latitude.\n",
        "        target_lon (float): Target longitude.\n",
        "\n",
        "    Returns:\n",
        "        pd.Series: The row of the closest location.\n",
        "    \"\"\"\n",
        "    df[\"distance\"] = np.sqrt((df[\"latitude\"] - target_lat) ** 2 + (df[\"longitude\"] - target_lon) ** 2)\n",
        "    return df.loc[df[\"distance\"].idxmin()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def plot_closest_location(df_ocean: pd.DataFrame, target_lat: float, target_lon: float) -> None:\n",
        "    \"\"\"\n",
        "    Plot the closest location in ocean data to the target latitude and longitude,\n",
        "    with a basemap background using Basemap.\n",
        "    \"\"\"\n",
        "\n",
        "    closest_location = find_closest_location(df_ocean, target_lat, target_lon)\n",
        "\n",
        "    # Mittelwerte für Kartenzentrum\n",
        "    mean_lat = df_ocean[\"latitude\"].mean()\n",
        "    mean_lon = df_ocean[\"longitude\"].mean()\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    # Erstelle Basemap\n",
        "    m = Basemap(\n",
        "        projection='lcc',\n",
        "        resolution='i',\n",
        "        lat_0=mean_lat,\n",
        "        lon_0=mean_lon,\n",
        "        width=1.2e6,\n",
        "        height=1.2e6,\n",
        "    )\n",
        "\n",
        "    # Kartenelemente zeichnen\n",
        "    m.drawcoastlines()\n",
        "    m.drawcountries()\n",
        "    m.drawstates()\n",
        "    m.drawmapboundary(fill_color=\"lightblue\")\n",
        "    m.fillcontinents(color=\"lightgray\", lake_color=\"lightblue\")\n",
        "\n",
        "    # Koordinaten konvertieren (long, lat) → Karten-Koordinaten (x, y)\n",
        "    x_ocean, y_ocean = m(df_ocean[\"longitude\"].values, df_ocean[\"latitude\"].values)\n",
        "    x_target, y_target = m(target_lon, target_lat)\n",
        "    x_closest, y_closest = m(closest_location.longitude, closest_location.latitude)\n",
        "\n",
        "    # Punkte plotten\n",
        "    m.scatter(x_ocean, y_ocean, color=\"blue\", label=\"Ocean Data\", s=10)\n",
        "    m.scatter(x_target, y_target, color=\"#0072B2\", marker=\"*\", label=\"Target Point\", s=200)\n",
        "    m.scatter(x_closest, y_closest, color=\"#E69F00\", marker=\"o\", label=\"Closest Point\", s=50)\n",
        "\n",
        "    plt.title(\"Closest Location in Ocean Data\", fontsize=14)\n",
        "    plt.legend(loc=\"upper right\")\n",
        "    m.drawparallels(np.arange(-360, 360, 1), labels=[1, 0, 0, 0], fontsize=10)\n",
        "    m.drawmeridians(np.arange(-360, 360, 1), labels=[0, 0, 0, 1], fontsize=10)\n",
        "    plt.show()\n",
        "\n",
        "target_lat = 54.5\n",
        "target_lon = 10.0\n",
        "plot_closest_location(df_ocean, target_lat, target_lon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def comparison_slev_sla(df_ocean: pd.DataFrame, df_insitu: pd.DataFrame, target_lat: float = 54.5, target_lon: float = 10.0) -> None:\n",
        "    \"\"\"\n",
        "    Compare the SLEV and SLA data by plotting them on the same graph.\n",
        "    \"\"\"\n",
        "\n",
        "    closest_location = find_closest_location(df_ocean, target_lat, target_lon)\n",
        "    # Filter the data for the closest location\n",
        "    df_ocean_target = df_ocean[\n",
        "        (df_ocean[\"latitude\"] == closest_location[\"latitude\"])\n",
        "        & (df_ocean[\"longitude\"] == closest_location[\"longitude\"])\n",
        "    ].reset_index(drop=True)\n",
        "\n",
        "\n",
        "    # Calculating Pearson correlation of SLEV and SLA\n",
        "    df_corr_ocean = df_ocean_target.copy()\n",
        "    df_corr_insitu = df_insitu.copy()\n",
        "\n",
        "    df_corr_ocean.index = pd.to_datetime(df_corr_ocean.index)\n",
        "    df_corr_insitu.index = pd.to_datetime(df_corr_insitu.index)\n",
        "    df_corr = pd.merge(df_corr_ocean[['sla']], df_corr_insitu[['slev']], left_index=True, right_index=True, how='inner')\n",
        "    corr = df_corr['slev'].corr(df_corr['sla'])\n",
        "    rmse = np.sqrt(np.mean((df_corr['slev'] - df_corr['sla']) ** 2))\n",
        "\n",
        "    # Plotting SLEV and SLA\n",
        "    alpha = 0.8\n",
        "    window_size = 24\n",
        "\n",
        "    rolling_mean_slev = df_insitu[\"slev\"].rolling(window=window_size).mean()\n",
        "    rolling_mean_sla = df_ocean_target[\"sla\"].rolling(window=window_size).mean()\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(df_insitu[\"time\"], df_insitu[\"slev\"], label=\"water level Flensburg (SLEV)\", color=\"#0072B2\", alpha=0.1)\n",
        "    plt.plot(df_ocean[\"time\"], df_ocean[\"sla\"], label=\"water level - closest point (SLA)\", color=\"#E69F00\", alpha=0.1)\n",
        "    plt.plot(df_insitu[\"time\"], rolling_mean_slev, label=\"water level Flensburg (SLEV) Rolling Mean\", color=\"#0072B2\", linestyle=\"-\", alpha=alpha)\n",
        "    plt.plot(df_ocean_target[\"time\"], rolling_mean_sla, label=\"water level - closest point (SLA) Rolling Mean\", color=\"#E69F00\", linestyle=\"-\", alpha=alpha)\n",
        "    # plot text with the correlation value\n",
        "\n",
        "    plt.title(f\"Comparison of SLEV and SLA \\n Correlation: {corr:.2f}, RMSE: {rmse:.2f}\", fontsize=14)\n",
        "    plt.xlabel(\"time\")\n",
        "    plt.ylabel(\"water level [m]\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # calcualte autocorrelation for SLEV and SLA for different lags\n",
        "    \n",
        "    df_corr_insitu = df_corr_insitu.loc[(df_corr_insitu['time'] >= df_corr_ocean['time'].min()) & (df_corr_insitu['time'] <= df_corr_ocean['time'].max())]\n",
        "    fig, ax = plt.subplots(2, 1, figsize=(12, 8))\n",
        "    plot_acf(df_insitu[\"slev\"], lags=100, ax=ax[0])\n",
        "    ax[0].set_title(\"Autocorrelation of SLEV\")\n",
        "    plot_acf(df_ocean_target[\"sla\"], lags=100, ax=ax[1])\n",
        "    ax[1].set_title(\"Autocorrelation of SLA\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "comparison_slev_sla(df_ocean=df_ocean, df_insitu=df_insitu, target_lat=target_lat, target_lon=target_lon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from statsmodels.tsa.stattools import acf, pacf\n",
        "\n",
        "n_lags = 100\n",
        "diff_series=df_insitu['slev'].diff(2)[2:]\n",
        "lag_acf=acf(diff_series, nlags=n_lags)\n",
        "lag_pacf=pacf(diff_series, nlags=n_lags, method='ols')\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(121)\n",
        "plt.plot(lag_acf)\n",
        "plt.axhline(y=0,linestyle='--',color='green')\n",
        "plt.axhline(y=-1.96/np.sqrt(len(diff_series)),linestyle='--',color='green')\n",
        "plt.axhline(y=1.96/np.sqrt(len(diff_series)),linestyle='--',color='green')\n",
        "plt.title('Autocorrelation Function')\n",
        "plt.subplot(122)\n",
        "plt.plot(lag_pacf)\n",
        "plt.axhline(y=0,linestyle='--',color='green')\n",
        "plt.axhline(y=-1.96/np.sqrt(len(diff_series)),linestyle='--',color='green')\n",
        "plt.axhline(y=1.96/np.sqrt(len(diff_series)),linestyle='--',color='green')\n",
        "plt.title('Partial Autocorrelation Function')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wie verhält sich Wind, Windrichtung bei den unterschiedlichen Sturmfluten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cartopy.feature as cfeature\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shapely.geometry\n",
        "import xarray as xr\n",
        "from joblib import Parallel, delayed\n",
        "from scipy.interpolate import griddata\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Funktion zur Landprüfung mit Cartopy\n",
        "def is_on_land(lon, lat):\n",
        "    land = cfeature.NaturalEarthFeature(\"physical\", \"land\", \"10m\")\n",
        "    for geom in land.geometries():\n",
        "        if geom.contains(shapely.geometry.Point(lon, lat)):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "# Funktion zum Erstellen der Landmaske\n",
        "def create_land_mask(lon_grid, lat_grid):\n",
        "    coords_list = [(lon, lat) for lat in lat_grid for lon in lon_grid]\n",
        "    mask_flat = Parallel(n_jobs=-1)(\n",
        "        delayed(lambda p: not is_on_land(*p))(p) for p in tqdm(coords_list)\n",
        "    )\n",
        "    return np.array(mask_flat).reshape(len(lat_grid), len(lon_grid))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.dates as mdates\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def lineplot_storm_surge(df, timepoints, ax=None):\n",
        "\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(18, 6))\n",
        "\n",
        "    timepoints_array = np.array(timepoints)\n",
        "    timepoint_min = timepoints_array.min()\n",
        "    timepoint_max = timepoints_array.max()\n",
        "    # Eingrenzen des Datenbereichs\n",
        "    df_plot = df.loc[\n",
        "        (df_insitu[\"time\"] >= timepoint_min - pd.Timedelta(hours=62)) & \n",
        "        (df_insitu[\"time\"] <= timepoint_max + pd.Timedelta(hours=62))\n",
        "    ].reset_index(drop=True)\n",
        "\n",
        "    # Plot SLEV\n",
        "    x = df_plot[\"time\"]\n",
        "    y = df_plot[\"slev\"]\n",
        "    ax.plot(x, y, label=\"SLEV\", color=\"royalblue\", linewidth=2)\n",
        "\n",
        "\n",
        "\n",
        "    # VLines + Text\n",
        "    for i, t in enumerate(timepoints):\n",
        "        ax.axvline(x=t, ymin=0, ymax=1, color=\"crimson\", linestyle=\"--\", alpha=0.6)\n",
        "        ax.text(\n",
        "            t,\n",
        "            y.mean(),\n",
        "            t.strftime(\"%Y-%m-%d %H:%M\"),\n",
        "            color=\"crimson\",\n",
        "            fontsize=9,\n",
        "            ha=\"center\",\n",
        "            rotation=90,\n",
        "            rotation_mode=\"anchor\"\n",
        "        )\n",
        "    # Format X-Achse\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d %H:%M\"))\n",
        "    ax.xaxis.set_major_locator(mdates.HourLocator(interval=4))\n",
        "    plt.xticks(rotation=90)\n",
        "\n",
        "    # Labels & Title\n",
        "    ax.set_title(\"Sea Level Elevation (SLEV) with Storm Surges\", fontsize=14, pad=15)\n",
        "    #ax.set_xlabel(\"Time\", fontsize=12)\n",
        "    ax.set_ylabel(\"Water Level [m]\", fontsize=12)\n",
        "\n",
        "    # for t in timepoints:\n",
        "    #     ax.axvline(x=t, ymin=0, ymax=1, color=\"crimson\", linestyle=\"--\", alpha=0.6, label=\"Storm Surge\")\n",
        "\n",
        "    # # Nur einmaliger Eintrag\n",
        "    # handles, labels = ax.get_legend_handles_labels()\n",
        "    # by_label = dict(zip(labels, handles))\n",
        "    # ax.legend(by_label.values(), by_label.keys(), loc=\"upper left\")\n",
        "\n",
        "\n",
        "    # Grid, Legend, Layout\n",
        "    ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "    ax.legend(loc=\"upper left\")\n",
        "    #plt.tight_layout()\n",
        "\n",
        "    #plt.show()\n",
        "    return ax\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "closest_location = find_closest_location(df_ocean, target_lat, target_lon)\n",
        "# Filter the data for the closest location\n",
        "df_ocean_target = df_ocean[\n",
        "    (df_ocean[\"latitude\"] == closest_location[\"latitude\"])\n",
        "    & (df_ocean[\"longitude\"] == closest_location[\"longitude\"])\n",
        "].reset_index(drop=True)\n",
        "\n",
        "# Calculating Pearson correlation of SLEV and SLA\n",
        "df_corr_ocean = df_ocean_target.copy()\n",
        "df_corr_insitu = df_insitu.copy()\n",
        "\n",
        "df_corr_ocean.index = pd.to_datetime(df_corr_ocean.index)\n",
        "df_corr_insitu.index = pd.to_datetime(df_corr_insitu.index)\n",
        "df_corr = pd.merge(df_corr_ocean[['sla']], df_corr_insitu[['slev']], left_index=True, right_index=True, how='inner')\n",
        "corr = df_corr['slev'].corr(df_corr['sla'])\n",
        "rmse = np.sqrt(np.mean((df_corr['slev'] - df_corr['sla']) ** 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "\n",
        "def grid_to_xarray(key, grid, lon_grid, lat_grid):\n",
        "    ds = xr.Dataset(\n",
        "            {\n",
        "                f\"{key}\": ((\"latitude\", \"longitude\"), grid),\n",
        "\n",
        "            },\n",
        "            coords={\n",
        "                \"latitude\": lat_grid,\n",
        "                \"longitude\": lon_grid,\n",
        "            },\n",
        "        )\n",
        "    return ds \n",
        "\n",
        "\n",
        "def plot_for_timepoint(timepoint, ax=None, grid_size_ocean=50, wind_grid_size=20, vmin=-1.0, vmax=1.5, plot_water_velocity_data=True, plot_wind_data=True):\n",
        "    \n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(12, 10))\n",
        "    df_weather_time = df_weather[df_weather[\"time\"] == timepoint]\n",
        "    df_ocean_time = df_ocean[df_ocean[\"time\"] == timepoint]\n",
        "\n",
        "    # add rmse to df_ocean_time[sla]\n",
        "    df_ocean_time[\"sla\"] += rmse\n",
        "\n",
        "    lon_grid = np.linspace(df_ocean_time[\"longitude\"].min(), df_ocean_time[\"longitude\"].max(), grid_size_ocean)\n",
        "    lat_grid = np.linspace(df_ocean_time[\"latitude\"].min(), df_ocean_time[\"latitude\"].max(), grid_size_ocean)\n",
        "    lon_mesh, lat_mesh = np.meshgrid(lon_grid, lat_grid)\n",
        "\n",
        "    sla_grid = griddata(\n",
        "        (df_ocean_time[\"longitude\"], df_ocean_time[\"latitude\"]),\n",
        "        df_ocean_time[\"sla\"],\n",
        "        (lon_mesh, lat_mesh),\n",
        "        method=\"linear\",\n",
        "    )\n",
        "\n",
        "    m = Basemap(\n",
        "        projection=\"cyl\",\n",
        "        resolution=\"i\",\n",
        "        llcrnrlon=lon_grid.min(),\n",
        "        urcrnrlon=lon_grid.max(),\n",
        "        llcrnrlat=lat_grid.min(),\n",
        "        urcrnrlat=lat_grid.max(),\n",
        "        ax=ax,\n",
        "    )\n",
        "    m.fillcontinents(color=\"grey\", lake_color=\"white\", alpha=0.5)\n",
        "    m.drawcoastlines()\n",
        "    m.drawcountries()\n",
        "\n",
        "    # plot target point\n",
        "    x_target, y_target = m(LON_FLENSBURG, LAT_FLENSBURG)  # Reihenfolge: (longitude, latitude)\n",
        "    m.scatter(x_target, y_target, color=\"green\", marker=\"*\", label=\"Target Point\", s=200) \n",
        "\n",
        "\n",
        "    # plot rectangle around target point\n",
        "    sub_box = {\n",
        "        \"lat_min\": 54.4, # 54.4\n",
        "        \"lat_max\": 55.5, # 55.5\n",
        "        \"lon_min\": 9.2,\n",
        "        \"lon_max\": 10.5 # 10.5\n",
        "        }\n",
        "    x_box = [sub_box[\"lon_min\"], sub_box[\"lon_max\"], sub_box[\"lon_max\"], sub_box[\"lon_min\"], sub_box[\"lon_min\"]]\n",
        "    y_box = [sub_box[\"lat_min\"], sub_box[\"lat_min\"], sub_box[\"lat_max\"], sub_box[\"lat_max\"], sub_box[\"lat_min\"]]\n",
        "    x_box, y_box = m(x_box, y_box)\n",
        "    ax.plot(x_box, y_box, color=\"green\", linestyle=\"--\", linewidth=2, label=\"Region of Interest\")\n",
        "    #ax.fill(x_box, y_box, color=\"white\", alpha=0.2)\n",
        "\n",
        "\n",
        "    # Create ocean grid\n",
        "    mask = create_land_mask(lon_grid, lat_grid)\n",
        "    sla_grid[~mask] = np.nan\n",
        "\n",
        "    x_mesh, y_mesh = m(lon_mesh, lat_mesh)\n",
        "    heatmap = m.pcolormesh(x_mesh, y_mesh, sla_grid, cmap=\"magma\", shading=\"auto\", vmin=vmin, vmax=vmax)\n",
        "\n",
        "\n",
        "    # Wasser Geschwindigkeitsdaten\n",
        "    # eastward and northward velocity\n",
        "    if plot_water_velocity_data:\n",
        "        water_uo = griddata(\n",
        "            (df_ocean_time[\"longitude\"], df_ocean_time[\"latitude\"]),\n",
        "            df_ocean_time[\"uo\"],\n",
        "            (lon_mesh, lat_mesh),\n",
        "            method=\"linear\",\n",
        "        )\n",
        "        water_vo = griddata(\n",
        "            (df_ocean_time[\"longitude\"], df_ocean_time[\"latitude\"]),\n",
        "            df_ocean_time[\"vo\"],\n",
        "            (lon_mesh, lat_mesh),\n",
        "            method=\"linear\",\n",
        "        )\n",
        "\n",
        "        # stride depends on the grid size\n",
        "        if grid_size_ocean <= 100:\n",
        "            stride = 1\n",
        "        elif grid_size_ocean <= 200:\n",
        "            stride = 4\n",
        "        elif grid_size_ocean <= 300:\n",
        "            stride = 6\n",
        "        elif grid_size_ocean <= 400:\n",
        "            stride = 8\n",
        "        elif grid_size_ocean <= 500:\n",
        "            stride = 12\n",
        "        elif grid_size_ocean <= 600:\n",
        "            stride = 16\n",
        "        elif grid_size_ocean <= 700:\n",
        "            stride = 20\n",
        "        elif grid_size_ocean <= 800:\n",
        "            stride = 24\n",
        "\n",
        "        water_uo[~mask] = np.nan\n",
        "        water_vo[~mask] = np.nan\n",
        "        #stride = 2  # z.B. jeden 3. Punkt nehmen, anpassbar\n",
        "        x_current = x_mesh[::stride, ::stride]\n",
        "        y_current = y_mesh[::stride, ::stride]\n",
        "        u_current = water_uo[::stride, ::stride]\n",
        "        v_current = water_vo[::stride, ::stride]\n",
        "\n",
        "        quiv_current = m.quiver(\n",
        "            x_current,\n",
        "            y_current,\n",
        "            u_current,\n",
        "            v_current,\n",
        "            scale=20,        # je nach Einheiten der uo/vo anpassen\n",
        "            color='grey',   # z.B. andere Farbe als Wind\n",
        "            width=0.002,    # dünner Pfeil\n",
        "            alpha=0.99,\n",
        "            label=\"Current\"\n",
        "        )\n",
        "        # ax.quiverkey(quiv_current, 0.92, 0.04, 20, '1 m/s Current', labelpos='E', \n",
        "        #             coordinates='axes', \n",
        "        #             color='grey')\n",
        "\n",
        "        ds_ocean_uo = grid_to_xarray(\"vo\", water_uo, lon_grid, lat_grid)\n",
        "        ds_ocean_vo = grid_to_xarray(\"uo\", water_vo, lon_grid, lat_grid)\n",
        "\n",
        "        # merge the datasets\n",
        "        ds_ocean_uo_vo= xr.merge([ds_ocean_uo, ds_ocean_vo])\n",
        "\n",
        "        # calculate the actual velocity with time included\n",
        "        ds_ocean_uo_vo['velocity'] = np.sqrt(ds_ocean_uo_vo[\"uo\"]**2 + ds_ocean_uo_vo[\"vo\"]**2)\n",
        "\n",
        "        # select the ocean current at the bbox\n",
        "        ds_ocean_uo_vo_bbox = ds_ocean_uo_vo.sel(\n",
        "            latitude=slice(sub_box[\"lat_min\"], sub_box[\"lat_max\"]),\n",
        "            longitude=slice(sub_box[\"lon_min\"], sub_box[\"lon_max\"]),\n",
        "        )\n",
        "\n",
        "\n",
        "        # get the max ocean current in the ds_ocean_uo_vo_bbox\n",
        "        max_ocean_velocity = ds_ocean_uo_vo_bbox[\"velocity\"].max().values\n",
        "\n",
        "     # Winddaten   \n",
        "    if plot_wind_data:\n",
        "        \n",
        "        lon_grid_wind = np.linspace(df_weather_time[\"longitude\"].min(), df_weather_time[\"longitude\"].max(), wind_grid_size)\n",
        "        lat_grid_wind = np.linspace(df_weather_time[\"latitude\"].min(), df_weather_time[\"latitude\"].max(), wind_grid_size)\n",
        "        lon_mesh_wind, lat_mesh_wind = np.meshgrid(lon_grid_wind, lat_grid_wind)\n",
        "\n",
        "        wind_speed_grid = griddata(\n",
        "            (df_weather_time[\"longitude\"], df_weather_time[\"latitude\"]),\n",
        "            df_weather_time[\"wind_speed_10m\"],\n",
        "            (lon_mesh_wind, lat_mesh_wind),\n",
        "            method=\"linear\",\n",
        "        )\n",
        "        wind_dir_grid = griddata(\n",
        "            (df_weather_time[\"longitude\"], df_weather_time[\"latitude\"]),\n",
        "            df_weather_time[\"wind_direction_10m\"],\n",
        "            (lon_mesh_wind, lat_mesh_wind),\n",
        "            method=\"linear\",\n",
        "        )\n",
        "\n",
        "        u = wind_speed_grid * -np.cos(np.deg2rad(wind_dir_grid))\n",
        "        v = wind_speed_grid * -np.sin(np.deg2rad(wind_dir_grid))\n",
        "        x_wind, y_wind = m(lon_mesh_wind, lat_mesh_wind)\n",
        "        quiv_wind = m.quiver(x_wind, y_wind, u, v, scale=1500, color=\"black\")\n",
        "        # Beispielhafte Quiverkey-Legende im Plot\n",
        "        #ax.quiverkey(quiv_wind, 0.92, 0.08, 10, '10 m/s Wind', labelpos='E', coordinates='axes', color='black')\n",
        "\n",
        "\n",
        "        # make xarray from wind_speed_grid and wind_dir_grid\n",
        "        ds_wind_speed = grid_to_xarray(\"wind_speed\", wind_speed_grid, lon_grid_wind, lat_grid_wind)\n",
        "        \n",
        "        # select the wind speed and direction at the bbox\n",
        "        ds_wind_speed_bbox = ds_wind_speed.sel(\n",
        "            latitude=slice(sub_box[\"lat_min\"], sub_box[\"lat_max\"]),\n",
        "            longitude=slice(sub_box[\"lon_min\"], sub_box[\"lon_max\"]),\n",
        "        )\n",
        "\n",
        "        # get the max wind speed in the ds_wind_bbox\n",
        "        max_wind_speed = ds_wind_speed_bbox[\"wind_speed\"].max().values\n",
        "        \n",
        "        # text on top of the box\n",
        "        # ax.text(\n",
        "        #     (sub_box[\"lon_min\"] + sub_box[\"lon_max\"]) / 2,\n",
        "        #     (sub_box[\"lat_max\"] - 0.1),\n",
        "        #     \"Target Box\",\n",
        "        #     color=\"green\",\n",
        "        #     fontsize=11,\n",
        "        #     ha=\"center\",\n",
        "        #     va=\"center\",\n",
        "        # )\n",
        "\n",
        "    ax.set_title(f\"Time: {pd.to_datetime(timepoint).strftime('%Y-%m-%d %H:%M')}\\n Max Wind Speed at Target Box {max_wind_speed:.3f} km/h \\n Max Water Velocity at Target Box {max_ocean_velocity:.3f} m/s\", fontsize=14, pad=15)\n",
        "    m.drawparallels(np.arange(0, 360, 2), labels=[1, 0, 0, 0])\n",
        "    m.drawmeridians(np.arange(0, 350, 2), labels=[0, 0, 0, 1])\n",
        "    \n",
        "    return heatmap\n",
        "\n",
        "\n",
        "def analyse_storm_surges(title: str = \"Storm Surges Analysis\", timepoints: list = None, grid_size_ocean=50, wind_grid_size=20, plot_water_velocity_data=True, plot_wind_data=True, save=False):\n",
        "    \n",
        "    fig = plt.figure(figsize=(20, 19))\n",
        "\n",
        "    # Neue Anordnung: 3 Zeilen, 2 Spalten → Zeitreihe oben, darunter 2x2 Heatmaps\n",
        "    gs = gridspec.GridSpec(3, 2, height_ratios=[0.4, 0.8, 1], hspace=0.2, wspace=0.15)\n",
        "\n",
        "    heatmaps = []\n",
        "    axes_heatmaps = []\n",
        "\n",
        "    timepoints_array = np.array(timepoints)\n",
        "    timepoint_min = timepoints_array.min()\n",
        "    timepoint_max = timepoints_array.max()\n",
        "\n",
        "    # Eingrenzen des Datenbereichs\n",
        "    df_plot = df_ocean.loc[\n",
        "        (df_ocean[\"time\"] >= timepoint_min - pd.Timedelta(hours=62)) & \n",
        "        (df_ocean[\"time\"] <= timepoint_max + pd.Timedelta(hours=62))\n",
        "    ].reset_index(drop=True)\n",
        "\n",
        "    # select the smallest sla and maximum sla\n",
        "    min_sla = df_plot[\"sla\"].min()\n",
        "    max_sla = df_plot[\"sla\"].max()\n",
        "    print(f\"Min SLA: {min_sla}, Max SLA: {max_sla}\")\n",
        "\n",
        "    # Zeitverlauf ganz oben über beide Spalten\n",
        "    ax_line = fig.add_subplot(gs[0, :])  # oberste Zeile, beide Spalten\n",
        "    lineplot_storm_surge(df_insitu, timepoints, ax=ax_line)\n",
        "    ax_line.set_title(\"Time Graph of Water Level Elevation in Flensburg\")\n",
        "    ax_line.set_position([0.1, 0.75, 0.8, 0.2])  # Adjust size and position\n",
        "\n",
        "    \n",
        "    # 2x2 Heatmaps darunter\n",
        "    min_sla_round = np.round(min_sla, 1)\n",
        "    max_sla_round = np.round(max_sla, 1)\n",
        "    for i, timepoint in enumerate(timepoints):\n",
        "        ax = fig.add_subplot(gs[i // 2 + 1, i % 2])  # Zeilen 1 und 2\n",
        "        \n",
        "        ax.set_position([0.1 + (i % 2) * 0.4, 0.1 + (i // 2) * 0.23, 0.35, 0.35])  # Adjust size and position [left, bottom, width, height]\n",
        "        axes_heatmaps.append(ax)\n",
        "        heatmap = plot_for_timepoint(timepoint, ax, grid_size_ocean, wind_grid_size, min_sla_round, max_sla_round, plot_water_velocity_data=plot_water_velocity_data, plot_wind_data=plot_wind_data)\n",
        "        heatmaps.append(heatmap)\n",
        "\n",
        "    # Gemeinsame Farbleiste rechts neben den Heatmaps\n",
        "    cbar_ax = fig.add_axes([0.87, 0.17, 0.02, 0.38])  # [left, bottom, width, height]\n",
        "    cbar = fig.colorbar(heatmaps[0], cax=cbar_ax, orientation=\"vertical\")\n",
        "    ticks = np.linspace(min_sla_round, max_sla_round, num=5)  # Anzahl der Ticks anpassen\n",
        "    cbar.set_ticks(ticks)\n",
        "    cbar.set_label(\"Water Level (m)\")\n",
        "\n",
        "    legend_elements = []\n",
        "    legend_elements.append(Line2D([0], [0], color='green', lw=2, label='Target Box', linestyle='--'))\n",
        "    \n",
        "    legend_elements.append(Line2D([0], [0], color='green', marker='*', markersize=15, linestyle='', label='Flensburg'))\n",
        "\n",
        "    \n",
        "    if plot_water_velocity_data:\n",
        "        legend_elements.append(Line2D([0], [0], color='grey', lw=4, marker=r'$\\rightarrow$', label='Ocean Current', linestyle=''))\n",
        "    if plot_wind_data:\n",
        "        legend_elements.append(Line2D([0], [0], color='black', lw=4, marker=r'$\\rightarrow$', label='Wind Direction', linestyle=''))\n",
        "\n",
        "\n",
        "    # Legende außerhalb der Plots, neben der Colorbar\n",
        "    fig.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(0.85, 0.59), frameon=True, title=\"Vector Legend\")\n",
        "\n",
        "    # Save the figure\n",
        "    if save:\n",
        "        fig_name = f'{title}_{grid_size_ocean}ozean_{wind_grid_size}wind.png'\n",
        "        fig.savefig(fig_name, bbox_inches='tight', dpi=300)\n",
        "\n",
        "    fig.suptitle(title, fontsize=16, y=0.99)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#plot_for_timepoint(timepoint=\"2023-01-01 00:00:00\", ax=None, grid_size_ocean=50, wind_grid_size=20, vmin=-1.0, vmax=1.5, plot_water_velocity_data=True, plot_wind_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_size_ocean = 200\n",
        "wind_grid_size = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyse von 2023-10-19 bis 2023-10-21\n",
        "timepoints = [\n",
        "    pd.Timestamp(\"2023-10-20 21:00\"), # links unten\n",
        "    pd.Timestamp(\"2023-10-21 16:00\"), # rechts unten\n",
        "    pd.Timestamp(\"2023-10-19 04:00\"), # links oben\n",
        "    pd.Timestamp(\"2023-10-20 13:00\"), # rechts oben\n",
        "]\n",
        "\n",
        "lineplot_storm_surge(df_insitu, timepoints, ax=ax_line)\n",
        "\n",
        "analyse_storm_surges(\n",
        "    title=\"Storm Surges Analysis from 2023-10-19 to 2023-10-21\", \n",
        "    timepoints=timepoints, \n",
        "    grid_size_ocean=grid_size_ocean, \n",
        "    wind_grid_size=wind_grid_size,\n",
        "    plot_water_velocity_data=True,\n",
        "    plot_wind_data=True,\n",
        "    save=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyse von 2024-01-02 bis 2024-01-05\n",
        "timepoints = [\n",
        "    pd.Timestamp(\"2024-01-03 22:00\"), # links unten\n",
        "    pd.Timestamp(\"2024-01-05 05:00\"), # rechts unten\n",
        "    pd.Timestamp(\"2024-01-02 18:00\"), # links oben\n",
        "    pd.Timestamp(\"2024-01-03 01:00\"), # rechts oben\n",
        "]\n",
        "\n",
        "analyse_storm_surges(\n",
        "    title=\"Storm Surges Analysis from 2024-01-02 to 2024-01-05\", \n",
        "    timepoints=timepoints, \n",
        "    grid_size_ocean=grid_size_ocean, \n",
        "    wind_grid_size=wind_grid_size,\n",
        "    plot_water_velocity_data=True,\n",
        "    plot_wind_data=True,\n",
        "    save=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyse von 2024-02-08 bis 2024-02-12\n",
        "timepoints = [\n",
        "    pd.Timestamp(\"2024-02-11 13:00\"), # 3 links unten\n",
        "    pd.Timestamp(\"2024-02-12 04:00\"), # 4 rechts unten\n",
        "    pd.Timestamp(\"2024-02-08 18:00\"), # 1 links oben\n",
        "    pd.Timestamp(\"2024-02-09 15:00\"), # 2 rechts oben\n",
        "]\n",
        "# get smallest timepoint and maximum timepoint\n",
        "timepoint_min = min(timepoints)\n",
        "timepoint_max = max(timepoints)\n",
        "\n",
        "analyse_storm_surges(\n",
        "    title=\"Storm Surges Analysis from 2024-02-08 to 2024-02-12\", \n",
        "    timepoints=timepoints, \n",
        "    grid_size_ocean=grid_size_ocean, \n",
        "    wind_grid_size=wind_grid_size,\n",
        "    plot_water_velocity_data=True,\n",
        "    plot_wind_data=True,\n",
        "    save=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wie vehält sich Wassergeschwindigkeit, Richtung bei den unterschiedlichen Sturmfluten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Analyse von 2023-10-19 bis 2023-10-21\n",
        "# timepoints = [\n",
        "#     pd.Timestamp(\"2023-10-20 21:00\"), # links unten\n",
        "#     pd.Timestamp(\"2023-10-21 16:00\"), # rechts unten\n",
        "#     pd.Timestamp(\"2023-10-19 04:00\"), # links oben\n",
        "#     pd.Timestamp(\"2023-10-20 13:00\"), # rechts oben\n",
        "# ]\n",
        "\n",
        "# analyse_storm_surges(\n",
        "#     title=\"Storm Surges Analysis from 2023-10-19 to 2023-10-21\", \n",
        "#     timepoints=timepoints, \n",
        "#     grid_size_ocean=grid_size_ocean, \n",
        "#     wind_grid_size=wind_grid_size,\n",
        "#     plot_water_velocity_data=True,\n",
        "#     plot_wind_data=False,\n",
        "#     save=True\n",
        "#     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Analyse von 2024-01-02 bis 2024-01-05\n",
        "# timepoints = [\n",
        "#     pd.Timestamp(\"2024-01-03 22:00\"), # links unten\n",
        "#     pd.Timestamp(\"2024-01-05 05:00\"), # rechts unten\n",
        "#     pd.Timestamp(\"2024-01-02 18:00\"), # links oben\n",
        "#     pd.Timestamp(\"2024-01-03 01:00\"), # rechts oben\n",
        "# ]\n",
        "# # \n",
        "# analyse_storm_surges(\n",
        "#     title=\"Storm Surges Analysis from 2024-01-02 to 2024-01-05\", \n",
        "#     timepoints=timepoints, \n",
        "#     grid_size_ocean=grid_size_ocean, \n",
        "#     wind_grid_size=wind_grid_size,\n",
        "#     plot_water_velocity_data=True,\n",
        "#     plot_wind_data=False,\n",
        "#     save=True\n",
        "#     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Analyse von 2024-02-08 bis 2024-02-12\n",
        "# timepoints = [\n",
        "#     pd.Timestamp(\"2024-02-11 13:00\"), # 3 links unten\n",
        "#     pd.Timestamp(\"2024-02-12 04:00\"), # 4 rechts unten\n",
        "#     pd.Timestamp(\"2024-02-08 18:00\"), # 1 links oben\n",
        "#     pd.Timestamp(\"2024-02-09 15:00\"), # 2 rechts oben\n",
        "# ]\n",
        "\n",
        "# analyse_storm_surges(\n",
        "#     title=\"Storm Surges Analysis from 2024-02-08 to 2024-02-12\", \n",
        "#     timepoints=timepoints, \n",
        "#     grid_size_ocean=grid_size_ocean, \n",
        "#     wind_grid_size=wind_grid_size,\n",
        "#     plot_water_velocity_data=True,\n",
        "#     plot_wind_data=False,\n",
        "#     save=True\n",
        "#     )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Korrelation zwischen SLEV und features on map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ocean = load_ocean_data(ocean_data_path, OCEAN_POINTS, verbose=False)\n",
        "df_ocean = process_df(df_ocean, drop_cols=[\"depth\"], verbose=False)\n",
        "\n",
        "df_weather = load_weather_data(weather_data_path, WEATHER_POINTS, verbose=False)\n",
        "df_weather = process_df(df_weather, verbose=False)\n",
        "\n",
        "df_insitu = load_insitu_data(verbose=False)\n",
        "df_insitu = process_flensburg_data(df_insitu, \n",
        "                                      start_time=df_ocean['time'].min(),\n",
        "                                      end_time=df_ocean['time'].max(),\n",
        "                                      verbose=False)\n",
        "\n",
        "df_insitu = group_data_hourly(df_insitu)\n",
        "df_insitu = process_df(df_insitu, drop_cols=[\"deph\"], verbose=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "resolution = 0.25 # 0.25 degrees\n",
        "\n",
        "def interpolate_xarray(ds, resolution=0.25, make_fine_grid=True, interpolate_nan=True):\n",
        "    \"\"\"\n",
        "    Interpolates the xarray dataset to a finer grid.\n",
        "\n",
        "    Parameters:\n",
        "        ds (xarray.Dataset): The input dataset to interpolate.\n",
        "        resolution (float): The desired resolution for the interpolation.\n",
        "\n",
        "    Returns:\n",
        "        xarray.Dataset: The interpolated dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    if interpolate_nan:\n",
        "        # Interpolation von NaN-Werten\n",
        "        ds = ds.interpolate_na(dim=\"time\", method=\"linear\")\n",
        "        ds = ds.interpolate_na(dim=\"latitude\", method=\"linear\")\n",
        "        ds = ds.interpolate_na(dim=\"longitude\", method=\"linear\")\n",
        "    \n",
        "    if make_fine_grid:\n",
        "        # Neues feineres Gitter erzeugen\n",
        "        new_lats = np.arange(ds.latitude.min(), ds.latitude.max(), resolution)\n",
        "        new_lons = np.arange(ds.longitude.min(), ds.longitude.max(), resolution)\n",
        "\n",
        "        # Interpolation\n",
        "        ds = ds.interp(latitude=new_lats, longitude=new_lons, method=\"linear\")\n",
        "  \n",
        "    return ds\n",
        "\n",
        "# Create xarray datasets from DataFrames\n",
        "# Interpolate the xarray to a higher resolution\n",
        "ds_ocean = df_ocean.set_index([\"time\", \"latitude\", \"longitude\"]).to_xarray()\n",
        "ds_ocean_interp = interpolate_xarray(ds_ocean, resolution=resolution, make_fine_grid=True, interpolate_nan=True)\n",
        "\n",
        "ds_weather = df_weather.set_index([\"time\", \"latitude\", \"longitude\"]).to_xarray()\n",
        "ds_weather_interp = interpolate_xarray(ds_weather, resolution=resolution, make_fine_grid=True, interpolate_nan=True)\n",
        "\n",
        "# Aline the time axes\n",
        "common_time = np.intersect1d(ds_ocean_interp.time.values, ds_weather_interp.time.values) # Finde common time points\n",
        "ds_ocean_interp = ds_ocean_interp.sel(time=common_time)\n",
        "ds_weather_interp = ds_weather_interp.sel(time=common_time)\n",
        "\n",
        "# Aline the lat and lon axes\n",
        "ds_weather_interp = ds_weather_interp.interp(\n",
        "    latitude=ds_ocean_interp.latitude,\n",
        "    longitude=ds_ocean_interp.longitude\n",
        ")\n",
        "\n",
        "ds_weather_interp = interpolate_xarray(ds_weather_interp, resolution=resolution, make_fine_grid=False, interpolate_nan=True)\n",
        "ds_ocean_interp = interpolate_xarray(ds_ocean_interp, resolution=resolution, make_fine_grid=False, interpolate_nan=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_ocean_mask(ds, land):\n",
        "\n",
        "    lon, lat = np.meshgrid(ds.longitude.values, ds.latitude.values)\n",
        "    points = [shapely.geometry.Point(x, y) for x, y in zip(lon.flatten(), lat.flatten())]\n",
        "\n",
        "    points_gdf = gpd.GeoDataFrame(geometry=points, crs=land.crs)\n",
        "    joined = gpd.sjoin(points_gdf, land, predicate=\"within\", how=\"left\")\n",
        "    on_land = ~joined.index_right.isna()\n",
        "\n",
        "    mask_land = np.array(on_land).reshape(lat.shape)\n",
        "    mask_ocean = ~mask_land\n",
        "\n",
        "    ocean_mask_xr = xr.DataArray(\n",
        "        mask_ocean,\n",
        "        coords={\"latitude\": ds.latitude, \"longitude\": ds.longitude},\n",
        "        dims=[\"latitude\", \"longitude\"]\n",
        "    )\n",
        "    return ocean_mask_xr\n",
        "\n",
        "land = gpd.read_file(geodatasets.get_path(\"naturalearth.land\"))\n",
        "ocean_mask = create_ocean_mask(ds_weather_interp, land)\n",
        "ds_weather_ocean_only = ds_weather_interp.where(ocean_mask)\n",
        "ds_ocean_ocean_only = ds_ocean_interp.where(ocean_mask)\n",
        "\n",
        "ds_ocean_weather_interp = xr.merge([ds_ocean_ocean_only, ds_weather_interp])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_ocean_weather_interp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def calculate_correlation_temporal_spatial(ds, df_ref, variable='sla', start_date=None, end_date=None, ax=None, title=None):\n",
        "    \"\"\"\n",
        "    Berechnet die Korrelation zwischen einer xarray-Zeitreihe und einer Pandas-Zeitreihe.\n",
        "    \n",
        "    Args:\n",
        "        ds_ocean (xarray.Dataset): Das xarray-Dataset mit den Ozeandaten.\n",
        "        df_ref (pandas.DataFrame): Das DataFrame mit den In-situ-Daten.\n",
        "        variable (str): Der Name der Variablen im xarray-Dataset, die korreliert werden soll.\n",
        "        \n",
        "    Returns:\n",
        "        correlations (numpy.ndarray): Ein Array mit den Korrelationswerten.\n",
        "    \"\"\"\n",
        "    \n",
        "    # 1. Sicherstellen, dass die Zeitstempel übereinstimmen\n",
        "    # 2. Leeres Array für Korrelationen\n",
        "    # 3. Schleife über alle Punkte\n",
        "    # 4. Plotten der Korrelationen\n",
        "\n",
        "    # 1. Deine Daten (angenommen du hast sie geladen als ds_ocean und df_ref)\n",
        "\n",
        "    fig = None\n",
        "\n",
        "    ocean_variables = ['bottomT', 'mlotst', 'siconc', 'sithick', \n",
        "                       'sla', 'so', 'sob', 'thetao', 'uo', 'vo', 'wo']\n",
        "    \n",
        "    air_variables = ['temperature_2m',\n",
        "                    'relative_humidity_2m', 'dew_point_2m', 'apparent_temperature',\n",
        "                    'precipitation', 'rain', 'showers', 'snowfall', 'weather_code',\n",
        "                    'pressure_msl', 'surface_pressure', 'cloud_cover', 'cloud_cover_low',\n",
        "                    'cloud_cover_mid', 'cloud_cover_high', 'et0_fao_evapotranspiration',\n",
        "                    'vapour_pressure_deficit', 'wind_speed_10m', 'wind_direction_10m',\n",
        "                    'wind_gusts_10m']\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    df_ref_filtered = df_ref.copy()\n",
        "    ds_filtered = ds.copy()\n",
        "\n",
        "    if start_date is not None and end_date is not None:\n",
        "        # Filtere die Daten nach dem angegebenen Zeitraum\n",
        "        df_ref_filtered = df_ref_filtered[(df_ref_filtered['time'] >= start_date) & (df_ref_filtered['time'] <= end_date)]\n",
        "        # Filtere die xarray-Daten nach dem angegebenen Zeitraum\n",
        "        ds_filtered = ds_filtered.sel(time=slice(start_date, end_date))\n",
        "    else:\n",
        "        # Wenn kein Zeitraum angegeben ist, verwende die gesamte Zeitreihe\n",
        "        start_date = ds_filtered['time'].min().values\n",
        "        end_date = ds_filtered['time'].max().values\n",
        "\n",
        "        # Filtere die xarray-Daten nach dem gesamten Zeitraum\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    # 3. slev-Zeitreihe (von df_ref_filtered)\n",
        "    slev_times = pd.to_datetime(df_ref_filtered['time'])\n",
        "    slev_values = df_ref_filtered['slev'].values\n",
        "\n",
        "    # 4. Sicherstellen, dass die Zeiten übereinstimmen\n",
        "    # Zeitstempel vom xarray\n",
        "    ocean_times = pd.to_datetime(ds_filtered['time'].values)\n",
        "\n",
        "    # Indexe der gemeinsamen Zeiten\n",
        "    common_times, idx_slev, idx_ocean = np.intersect1d(slev_times, ocean_times, return_indices=True)\n",
        "\n",
        "    # neue Zeitreihen\n",
        "    slev_values_common = slev_values[idx_slev]\n",
        "    ocean_times_common = ocean_times[idx_ocean]\n",
        "\n",
        "    # 5. Leeres Array für Korrelationen\n",
        "    correlations = np.full((len(ds_filtered.latitude), len(ds_filtered.longitude)), np.nan)\n",
        "\n",
        "    # 6. Schleife über alle Punkte\n",
        "    for i, lat in enumerate(ds_filtered.latitude.values):\n",
        "        for j, lon in enumerate(ds_filtered.longitude.values):\n",
        "            # Zeitreihe an diesem Punkt\n",
        "            ts = ds_filtered[variable].isel(latitude=i, longitude=j).values\n",
        "            \n",
        "            if np.all(np.isnan(ts)):  # Wenn nur NaNs -> überspringen\n",
        "                continue\n",
        "            \n",
        "            # nur gemeinsame Zeiten auswählen\n",
        "            ts_common = ts[idx_ocean]\n",
        "            \n",
        "            # Wenn zu viele NaNs, überspringen\n",
        "            if np.isnan(ts_common).mean() > 0.3:  # z.B. >30% fehlende Werte\n",
        "                continue\n",
        "            \n",
        "            # NaNs behandeln\n",
        "            mask = ~np.isnan(ts_common) & ~np.isnan(slev_values_common)\n",
        "            if np.sum(mask) < 10:  # Weniger als 10 gültige Werte\n",
        "                continue\n",
        "            \n",
        "            # Korrelation berechnen\n",
        "            corr = np.corrcoef(ts_common[mask], slev_values_common[mask])[0, 1]\n",
        "            correlations[i, j] = corr\n",
        "\n",
        "    # 7. Plotten der Korrelationen\n",
        "\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(14, 12))\n",
        "        created_fig = True\n",
        "    else:\n",
        "        created_fig = False\n",
        "\n",
        "\n",
        "    m = Basemap(projection='cyl', resolution='i',\n",
        "                llcrnrlon=ds_filtered.longitude.min(), urcrnrlon=ds_filtered.longitude.max(),\n",
        "                llcrnrlat=ds_filtered.latitude.min(), urcrnrlat=ds_filtered.latitude.max(), ax=ax)\n",
        "\n",
        "    if variable in air_variables:\n",
        "        m.drawcoastlines(ax=ax)\n",
        "        m.drawcountries(ax=ax)\n",
        "        m.drawmapboundary(fill_color='white', ax=ax)\n",
        "        m.fillcontinents(color='lightgrey', lake_color='white', ax=ax)\n",
        "        heatmap = ax.pcolormesh(ds_filtered.longitude, ds_filtered.latitude, correlations, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "        plt.colorbar(heatmap, label='Pearson correlation coefficient', orientation='horizontal', pad=0.05, ax=ax)\n",
        "        ax.scatter(df_ref_filtered['longitude'], df_ref_filtered['latitude'], c='green', s=200, label='Flensburg', marker='*')\n",
        "\n",
        "    m.drawparallels(np.arange(-360., 360, 1.), labels=[1, 0, 0, 0])\n",
        "    m.drawmeridians(np.arange(-360., 360, 1.), labels=[0, 0, 0, 1])\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    if variable in ocean_variables:\n",
        "        heatmap = ax.pcolormesh(ds_filtered.longitude, ds_filtered.latitude, correlations, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "        plt.colorbar(heatmap, label='Pearson correlation coefficient', orientation='horizontal', pad=0.05, ax=ax)\n",
        "        m.drawcoastlines(ax=ax)\n",
        "        m.drawcountries(ax=ax)\n",
        "        m.drawmapboundary(fill_color='white', ax=ax)\n",
        "        m.fillcontinents(color='lightgrey', lake_color='white', ax=ax)\n",
        "        ax.scatter(df_ref_filtered['longitude'], df_ref_filtered['latitude'], c='green', s=200, label='Flensburg', marker='*') \n",
        "    \n",
        "    # Set title to describe the variable\n",
        "    if variable in WEATHER_DICT.keys():\n",
        "        var_name = WEATHER_DICT[variable]['description'].lower()\n",
        "    if variable in OCEAN_DICT.keys():\n",
        "        var_name = OCEAN_DICT[variable]['description'].lower()\n",
        "    else:\n",
        "        var_name = variable\n",
        "    \n",
        "    start_date_str = pd.to_datetime(start_date).strftime('%Y-%m-%d %H:%M')\n",
        "    end_date_str = pd.to_datetime(end_date).strftime('%Y-%m-%d %H:%M')\n",
        "    if title is not None:\n",
        "\n",
        "        plt.title(title, fontsize=10, pad=15)\n",
        "    else:\n",
        "        plt.title(f'{start_date_str} to {end_date_str}', fontsize=10, pad=15)\n",
        "        \n",
        "    plt.legend(loc='upper right')\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if created_fig:\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    return heatmap\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variables = ['sla', 'uo', 'vo', 'wind_speed_10m', 'wind_direction_10m', 'surface_pressure']\n",
        "#variables = ds_ocean_weather_interp.data_vars.keys()\n",
        "#variables = ['wind_speed_10m']\n",
        "\n",
        "for variable in variables:\n",
        "    print(f\"Calculating correlation for {variable}\")\n",
        "    calculate_correlation_temporal_spatial(ds_ocean_weather_interp, df_insitu, variable=variable, \n",
        "                                           #start_date=\"2023-10-19\", end_date=\"2023-10-21\"\n",
        "                                           )\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "start_date = ds_ocean_weather_interp['time'].min().values\n",
        "end_date = ds_ocean_weather_interp['time'].max().values\n",
        "\n",
        "# round datetime to YYYY-MM-DD HH:MM\n",
        "start_date = pd.to_datetime(start_date).strftime('%Y-%m-%d %H:%M')\n",
        "end_date = pd.to_datetime(end_date).strftime('%Y-%m-%d %H:%M')\n",
        "\n",
        "variables = ['sla', 'uo', 'vo', 'wind_speed_10m', 'wind_direction_10m', 'surface_pressure']\n",
        "variables\n",
        "\n",
        "def plot_correlations(variables, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Plots the correlations between ocean variables and Flensburg SLEV.\n",
        "    \n",
        "    Args:\n",
        "        variables (list): List of variable names to plot.\n",
        "        start_date (str): Start date for the analysis.\n",
        "        end_date (str): End date for the analysis.\n",
        "    \"\"\"\n",
        "    n_cols = 3\n",
        "    n_rows = (len(variables) + n_cols - 1) // n_cols\n",
        "\n",
        "    fig = plt.figure(figsize=(8 * n_cols, 5 * n_rows))\n",
        "    gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)\n",
        "\n",
        "    fig.suptitle(f\"Correlation between Ocean Variables and Flensburg SLEV from {start_date} to {end_date}\", fontsize=20, y=0.98)\n",
        "\n",
        "    for idx, variable in enumerate(variables):\n",
        "        print(f\"Calculating correlation for {variable}\")\n",
        "        ax = fig.add_subplot(gs[idx])\n",
        "        calculate_correlation_temporal_spatial(\n",
        "            ds_ocean_weather_interp,\n",
        "            df_insitu,\n",
        "            variable=variable,\n",
        "            ax=ax,\n",
        "            start_date=start_date,\n",
        "            end_date=end_date,\n",
        "        )\n",
        "\n",
        "    # Statt tight_layout --> subplots_adjust\n",
        "    fig.subplots_adjust(top=0.92, hspace=0.1, wspace=0.1)  # <-- manuell fein justieren!\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compare_correlations(timepoints:list, variable:str):\n",
        "    \n",
        "    \n",
        "    n_cols = 3\n",
        "    n_rows = (len(timepoints) + n_cols -1) // n_cols\n",
        "    fig = plt.figure(figsize=(8 * n_cols, 5 * n_rows))\n",
        "    gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)\n",
        "\n",
        "    if variable in WEATHER_DICT.keys():\n",
        "        var_name = WEATHER_DICT[variable]['description'].lower()\n",
        "        var_explaination = WEATHER_DICT[variable]['explanation']\n",
        "        #var_unit = WEATHER_DICT[variable]['unit']\n",
        "    if variable in OCEAN_DICT.keys():\n",
        "        var_name = OCEAN_DICT[variable]['description'].lower()\n",
        "        var_explaination = OCEAN_DICT[variable]['explanation']\n",
        "        #var_unit = WEATHER_DICT[variable]['unit']\n",
        "    else:\n",
        "        var_name = variable\n",
        "        var_explaination = \"\"\n",
        "        #var_unit = \"\"\n",
        "    fig.suptitle(f\"Correlation between Flensburg SLEV and {var_name} \\n{var_explaination}\", fontsize=20, y=0.98)\n",
        "    \n",
        "\n",
        "    for idx, timepoint in tqdm(enumerate(timepoints), total=len(timepoints)):\n",
        "\n",
        "        start_date = timepoint - pd.Timedelta(days=3)\n",
        "        end_date = timepoint + pd.Timedelta(days=3)\n",
        "        ax = fig.add_subplot(gs[idx])\n",
        "        calculate_correlation_temporal_spatial(\n",
        "            ds_ocean_weather_interp,\n",
        "            df_insitu,\n",
        "            variable=variable,\n",
        "            ax=ax,\n",
        "            start_date=start_date,\n",
        "            end_date=end_date\n",
        "        )\n",
        "    fig.subplots_adjust(top=0.92, hspace=0.1, wspace=0.1)  # <-- manuell fein justieren!\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datetime\n",
        "timepoints_all = sorted(set(df_ocean[\"time\"]) & set(df_weather[\"time\"]))\n",
        "\n",
        "sturm_surge_list = [datetime.datetime(2023, 2, 25, 17, 0),\n",
        "                datetime.datetime(2023, 4, 1, 12, 0),\n",
        "                datetime.datetime(2023, 10, 7, 20, 0),\n",
        "                datetime.datetime(2023, 10, 20, 0, 0),\n",
        "                datetime.datetime(2024, 1, 3, 9, 0),\n",
        "                datetime.datetime(2024, 2, 9, 18, 0),\n",
        "                datetime.datetime(2024, 12, 9, 16, 0),\n",
        "                ]\n",
        "variables = ds_ocean_weather_interp.data_vars.keys()\n",
        "for variable in variables:\n",
        "    print(f\"Calculating correlation for {variable}\")\n",
        "    compare_correlations(timepoints=sturm_surge_list, variable=variable)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_date = ds_ocean_weather_interp['time'].min().values\n",
        "end_date = ds_ocean_weather_interp['time'].max().values\n",
        "\n",
        "# round datetime to YYYY-MM-DD HH:MM\n",
        "start_date = pd.to_datetime(start_date).strftime('%Y-%m-%d %H:%M')\n",
        "end_date = pd.to_datetime(end_date).strftime('%Y-%m-%d %H:%M')\n",
        "\n",
        "variables = ds_ocean_weather_interp.data_vars.keys()\n",
        "\n",
        "plot_correlations(variables, start_date, end_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "start_date = datetime.datetime(2023, 10, 17, 0, 0).strftime(\"%Y-%m-%d %H:%M\")\n",
        "end_date = datetime.datetime(2023, 10, 23, 0, 0).strftime(\"%Y-%m-%d %H:%M\")\n",
        "\n",
        "variables = ds_ocean_weather_interp.data_vars.keys()\n",
        "\n",
        "plot_water_level_anomalies(df_insitu, start_date=start_date, end_date=end_date)\n",
        "plot_correlations(\n",
        "    variables,\n",
        "    start_date=start_date,\n",
        "    end_date=end_date\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "sturm_surge_list = [datetime.datetime(2023, 2, 25, 17, 0),\n",
        "                    datetime.datetime(2023, 4, 1, 12, 0),\n",
        "                    datetime.datetime(2023, 10, 7, 20, 0),\n",
        "                    datetime.datetime(2023, 10, 20, 0, 0),\n",
        "                    datetime.datetime(2024, 2, 9, 18, 0),\n",
        "                    datetime.datetime(2024, 12, 9, 16, 0),\n",
        "                    ]\n",
        "\n",
        "for time in sturm_surge_list:\n",
        "    start_time = time - datetime.timedelta(days=1)\n",
        "    end_time = time + datetime.timedelta(days=1)\n",
        "    df_insitu_sturm = df_insitu[(df_insitu[\"time\"] >= start_time) & (df_insitu[\"time\"] <= end_time)]\n",
        "    plot_water_level_anomalies(df_insitu_sturm, start_date=start_date, end_date=end_date)\n",
        "    plot_correlations(\n",
        "        variables,\n",
        "        start_date=start_time,\n",
        "        end_date=end_time\n",
        "    )\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Correlaion just at sturm surges \n",
        "\n",
        "df_surge = df_insitu.copy()\n",
        "df_surge = df_surge.loc[df_surge['slev'] >= 0.5]\n",
        "start_date = df_surge['time'].min()\n",
        "end_date = df_surge['time'].max()\n",
        "# round datetime to YYYY-MM-DD HH:MM\n",
        "start_date = pd.to_datetime(start_date).strftime('%Y-%m-%d %H:%M')\n",
        "end_date = pd.to_datetime(end_date).strftime('%Y-%m-%d %H:%M')\n",
        "variables = ds_ocean_weather_interp.data_vars.keys()\n",
        "plot_water_level_anomalies(df_surge, start_date=start_date, end_date=end_date)\n",
        "plot_correlations(\n",
        "    variables,\n",
        "    start_date=start_date,\n",
        "    end_date=end_date\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_weather.showers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lassen sich Korrelationen zwischen den Features und dem Wasserpegel (sla) erkennen?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ocean = load_ocean_data(ocean_data_path, OCEAN_POINTS, verbose=False)\n",
        "df_ocean = process_df(df_ocean, drop_cols=[\"depth\"], verbose=False)\n",
        "\n",
        "df_weather = load_weather_data(weather_data_path, WEATHER_POINTS, verbose=False)\n",
        "df_weather = process_df(df_weather, verbose=False)\n",
        "\n",
        "df_insitu = load_insitu_data(verbose=False)\n",
        "df_insitu = process_flensburg_data(df_insitu, \n",
        "                                      start_time=df_ocean['time'].min(),\n",
        "                                      end_time=df_ocean['time'].max(),\n",
        "                                      verbose=False)\n",
        "\n",
        "df_insitu = group_data_hourly(df_insitu)\n",
        "df_insitu = process_df(df_insitu, drop_cols=[\"deph\"], verbose=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import geodatasets\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "\n",
        "resolution = 0.25 # 0.25 degrees\n",
        "\n",
        "def interpolate_xarray(ds, resolution=0.25, make_fine_grid=True, interpolate_nan=True):\n",
        "    \"\"\"\n",
        "    Interpolates the xarray dataset to a finer grid.\n",
        "\n",
        "    Parameters:\n",
        "        ds (xarray.Dataset): The input dataset to interpolate.\n",
        "        resolution (float): The desired resolution for the interpolation.\n",
        "\n",
        "    Returns:\n",
        "        xarray.Dataset: The interpolated dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    if interpolate_nan:\n",
        "        # Interpolation von NaN-Werten\n",
        "        ds = ds.interpolate_na(dim=\"time\", method=\"linear\")\n",
        "        ds = ds.interpolate_na(dim=\"latitude\", method=\"linear\")\n",
        "        ds = ds.interpolate_na(dim=\"longitude\", method=\"linear\")\n",
        "    \n",
        "    if make_fine_grid:\n",
        "        # Neues feineres Gitter erzeugen\n",
        "        new_lats = np.arange(ds.latitude.min(), ds.latitude.max(), resolution)\n",
        "        new_lons = np.arange(ds.longitude.min(), ds.longitude.max(), resolution)\n",
        "\n",
        "        # Interpolation\n",
        "        ds = ds.interp(latitude=new_lats, longitude=new_lons, method=\"linear\")\n",
        "  \n",
        "    return ds\n",
        "\n",
        "# Create xarray datasets from DataFrames\n",
        "# Interpolate the xarray to a higher resolution\n",
        "ds_ocean = df_ocean.set_index([\"time\", \"latitude\", \"longitude\"]).to_xarray()\n",
        "ds_ocean_interp = interpolate_xarray(ds_ocean, resolution=resolution, make_fine_grid=True, interpolate_nan=True)\n",
        "\n",
        "ds_weather = df_weather.set_index([\"time\", \"latitude\", \"longitude\"]).to_xarray()\n",
        "ds_weather_interp = interpolate_xarray(ds_weather, resolution=resolution, make_fine_grid=True, interpolate_nan=True)\n",
        "\n",
        "# Aline the time axes\n",
        "common_time = np.intersect1d(ds_ocean_interp.time.values, ds_weather_interp.time.values) # Finde common time points\n",
        "ds_ocean_interp = ds_ocean_interp.sel(time=common_time)\n",
        "ds_weather_interp = ds_weather_interp.sel(time=common_time)\n",
        "\n",
        "# Aline the lat and lon axes\n",
        "ds_weather_interp = ds_weather_interp.interp(\n",
        "    latitude=ds_ocean_interp.latitude,\n",
        "    longitude=ds_ocean_interp.longitude\n",
        ")\n",
        "\n",
        "ds_weather_interp = interpolate_xarray(ds_weather_interp, resolution=resolution, make_fine_grid=False, interpolate_nan=True)\n",
        "ds_ocean_interp = interpolate_xarray(ds_ocean_interp, resolution=resolution, make_fine_grid=False, interpolate_nan=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_ocean_mask(ds, land):\n",
        "\n",
        "    lon, lat = np.meshgrid(ds.longitude.values, ds.latitude.values)\n",
        "    points = [shapely.geometry.Point(x, y) for x, y in zip(lon.flatten(), lat.flatten())]\n",
        "\n",
        "    points_gdf = gpd.GeoDataFrame(geometry=points, crs=land.crs)\n",
        "    joined = gpd.sjoin(points_gdf, land, predicate=\"within\", how=\"left\")\n",
        "    on_land = ~joined.index_right.isna()\n",
        "\n",
        "    mask_land = np.array(on_land).reshape(lat.shape)\n",
        "    mask_ocean = ~mask_land\n",
        "\n",
        "    ocean_mask_xr = xr.DataArray(\n",
        "        mask_ocean,\n",
        "        coords={\"latitude\": ds.latitude, \"longitude\": ds.longitude},\n",
        "        dims=[\"latitude\", \"longitude\"]\n",
        "    )\n",
        "    return ocean_mask_xr\n",
        "\n",
        "land = gpd.read_file(geodatasets.get_path(\"naturalearth.land\"))\n",
        "ocean_mask = create_ocean_mask(ds_weather_interp, land)\n",
        "ds_weather_ocean_only = ds_weather_interp.where(ocean_mask)\n",
        "ds_ocean_ocean_only = ds_ocean_interp.where(ocean_mask)\n",
        "\n",
        "ds_ocean_weather_interp = xr.merge([ds_ocean_ocean_only, ds_weather_interp])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculating Bivariate Moran’s I "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Erklärung:** \n",
        "\n",
        "**Abgrenzung zu Korrelation und zeitlicher Autokorrelation**\n",
        "Bei der Berechnung der statistischen Korrelation werden zwei Variablen (x,y) bei zwei oder mehr Beobachtungen betrachtet; bei der räumlichen Autokorrelation hingegen eine Variable x an zwei oder mehr Orten.[3]\n",
        "\n",
        "Während die zeitliche Autokorrelation die Beziehungen der Ausprägungen einer Variablen mit sich selbst über die Zeit beschreibt, beschreibt die räumliche Autokorrelation die Ausprägungen einer Variablen mit sich selbst im Raum. \n",
        "\n",
        "**Berechnung**\n",
        "*Positive räumliche Autokorrelation *liegt dann vor, wenn nahe beieinander liegende Orte einander mit höherer Wahrscheinlichkeit ähnlich sind als weiter voneinander entfernte Orte. Das heißt: Positive räumliche Autokorrelation liegt vor, wenn Orte dazu tendieren, im Hinblick auf eine Eigenschaft Cluster zu bilden. Positive räumliche Autokorrelation ist eine empirische Manifestation von [Toblers](https://de.wikipedia.org/wiki/Erstes_Gesetz_der_Geographie) „Erstem Gesetz der Geographie“.\n",
        "\n",
        "*Negative räumliche Autokorrelation* liegt dann vor, wenn benachbarte Orte im Vergleich zu zufälliger Anordnung[5] unterschiedliche Eigenschaftswerte aufweisen. Bei Phänomenen, die mit Lebewesen (Tieren, Pflanzen) verbunden sind, wird negative Autokorrelation häufig durch Wettbewerb und Verdrängung verursacht.\n",
        "d\n",
        "*Keine räumliche Autokorrelation* liegt vor, wenn die Orte im Hinblick auf eine Eigenschaft zufällig angeordnet sind, also keine ausgeprägten Cluster aufweisen.\n",
        "\n",
        "[Wikipedia](https://de.wikipedia.org/wiki/Räumliche_Autokorrelation?utm_source=chatgpt.com) \n",
        "\n",
        "**Was ist räumliche Autokorrelation (spatial autocorrelatio**n)?\n",
        "\n",
        "Räumliche Autokorrelation beschreibt, wie stark der Wert einer Variablen an einem Ort mit den Werten derselben Variablen an anderen Orten zusammenhängt.\n",
        "\n",
        "**Vergleich mit klassischer Korrelation:**\n",
        "Normale (statistische) Korrelation:\n",
        "→ Fragt: \"Wie hängen zwei verschiedene Variablen miteinander zusammen?\"\n",
        "Beispiel: Wenn der Luftdruck steigt, sinkt vielleicht die Regenwahrscheinlichkeit.\n",
        "Räumliche Autokorrelation:\n",
        "→ Fragt: \"Wie hängt der Wert einer einzigen Variable an einem Ort mit den Werten derselben Variable an benachbarten Orten zusammen?\"\n",
        "Beispiel: Ist die Wasserhöhe an Punkt A ähnlich wie an den umliegenden Punkten?\n",
        "\n",
        "**Und wie unterscheidet sich das von zeitlicher Autokorrelation?**\n",
        "Zeitliche Autokorrelation:\n",
        "→ Fragt: \"Wie hängt ein Wert heute mit den Werten derselben Variablen in der Vergangenheit oder Zukunft zusammen?\"\n",
        "Beispiel: Die Temperatur heute hängt oft mit der Temperatur gestern zusammen.\n",
        "Räumliche Autokorrelation:\n",
        "→ Fragt: \"Wie hängt der Wert an einem Ort mit Werten an anderen Orten zusammen?\"\n",
        "\n",
        "**Achtung!!**\n",
        "Verwende den bivariaten Moran’s I, wenn du den räumlichen Zusammenhang zwischen zwei Variablen in geografischen Daten untersuchen möchtest. Dieser berücksichtigt, wie benachbarte Gebiete miteinander korrelieren und wie sich räumliche Muster bilden.\n",
        "Beispiel: Du analysierst, ob hohe Wasserhöhen in einer Region mit hohen Wasserhöhen in den benachbarten Regionen zusammenhängen und ob der Luftdruck in benachbarten Regionen ebenfalls ähnliche Werte aufweist.\n",
        "Verwende den Pearson’s R, wenn du den linearen Zusammenhang zwischen zwei Variablen messen möchtest, ohne die räumliche Abhängigkeit zu berücksichtigen. Dies ist besonders nützlich, wenn du den direkten Zusammenhang zwischen zwei Variablen untersuchen möchtest, ohne auf ihre geografische Lage zu achten.\n",
        "Beispiel: Du möchtest wissen, ob es einen linearen Zusammenhang zwischen der Wasserhöhe und dem Luftdruck gibt, unabhängig von den geografischen Standorten der Daten.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "\n",
        "#from splot.esda import moran_bv_plot\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "from esda.moran import Moran_BV\n",
        "from libpysal.weights import KNN\n",
        "from shapely.geometry import Point\n",
        "from tqdm import tqdm  # Fortschrittsbalken für test_k\n",
        "\n",
        "\n",
        "def calculating_morans_I(ds, var1: str, var2: str, time: str, k=3, plot=False, test_k=False):\n",
        "    # 1. Zeitschritt auswählen\n",
        "    ds = ds.sel(time=time)\n",
        "\n",
        "    # 2. Koordinaten extrahieren\n",
        "    lat, lon = np.meshgrid(ds.latitude.values, ds.longitude.values, indexing='ij')\n",
        "    coords = np.column_stack([lat.ravel(), lon.ravel()])\n",
        "    gdf = gpd.GeoDataFrame({\n",
        "        var1: ds[var1].values.ravel(),\n",
        "        var2: ds[var2].values.ravel()\n",
        "    }, geometry=[Point(xy) for xy in coords])\n",
        "\n",
        "    # 3. NaNs entfernen\n",
        "    gdf = gdf.dropna(subset=[var1, var2]).reset_index(drop=True)\n",
        "\n",
        "    # 4. KNN Spatial Weights\n",
        "    if len(gdf) <= k:\n",
        "        raise ValueError(f\"k={k} is too large for the dataset size of {len(gdf)}\")\n",
        "    w = KNN.from_dataframe(gdf, k=k)\n",
        "    w.transform = \"r\"\n",
        "\n",
        "    # 5. Moran's I berechnen\n",
        "    x = gdf[var1]\n",
        "    y = gdf[var2]\n",
        "    moran_bv = Moran_BV(x, y, w)\n",
        "\n",
        "    # 6. Optional: K-Test\n",
        "    if test_k:\n",
        "        list_k = np.arange(3, min(50, len(gdf)), 3)\n",
        "        results = []\n",
        "\n",
        "        for k_ in tqdm(list_k, desc=\"Testing k values\"):\n",
        "            if len(gdf) <= k_:\n",
        "                continue\n",
        "            try:\n",
        "                w_ = KNN.from_dataframe(gdf, k=k_)\n",
        "                w_.transform = \"r\"\n",
        "                m_bv = Moran_BV(x, y, w_)\n",
        "                results.append({\"k\": k_, \"Moran's I\": m_bv.I, \"p-value\": m_bv.p_sim})\n",
        "            except Exception as e:\n",
        "                print(f\"Fehler bei k={k_}: {e}\")\n",
        "\n",
        "        df_results = pd.DataFrame(results)\n",
        "        print(df_results)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # 7. Optional: Plot\n",
        "    if plot:\n",
        "        print(f\"Bivariate Moran’s I: {moran_bv.I:.4f}\")\n",
        "        print(f\"P-Wert (Monte Carlo): {moran_bv.p_sim:.4f}\")\n",
        "\n",
        "        z_x = (x - x.mean()) / x.std()\n",
        "        z_y = (y - y.mean()) / y.std()\n",
        "        wz_y = w.sparse @ z_y\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.scatter(z_x, wz_y, alpha=0.5)\n",
        "        plt.axhline(0, color='red', linestyle='--')\n",
        "        plt.axvline(0, color='red', linestyle='--')\n",
        "        plt.title(\"Bivariate Moran's I Scatter Plot\")\n",
        "        plt.xlabel(\"Variable X (Standardized)\")\n",
        "        plt.ylabel(\"Spatial Lag of Y (Standardized)\")\n",
        "        plt.grid(True, linestyle='--', alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return moran_bv.I, moran_bv.p_sim\n",
        "\n",
        "\n",
        "# Usage\n",
        "time = \"2024-10-20 19:00\"\n",
        "var1 = \"sla\"\n",
        "var2 = \"pressure_msl\"\n",
        "\n",
        "morans_I, morans_p = calculating_morans_I(ds_ocean_weather_interp, var1=var1, var2=var2, time=time, k=8, plot=False, test_k=True)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# make list of times between 2024-01-02 18:00 and 2024-01-05 05:00\n",
        "start = df_ocean[\"time\"].min()\n",
        "end = df_ocean[\"time\"].max()\n",
        "\n",
        "start = \"2023-10-01 00:00\"\n",
        "end = \"2023-11-01 00:00\"\n",
        "timepoints = pd.date_range(start=start, end=end, freq=\"1h\")\n",
        "\n",
        "\n",
        "\n",
        "var1 = \"sla\"\n",
        "var2 = \"wind_speed_10m\"\n",
        "\n",
        "list_morans_I = []\n",
        "list_morans_p = []\n",
        "for time in timepoints:\n",
        "    #print(f\"Calculating Moran's I for time: {time}\")\n",
        "    # Calculate Moran's I for each timepoint\n",
        "    morans_I, morans_p = calculating_morans_I(ds_ocean_weather_interp, var1=var1, var2=var2, time=time, k=5, plot=False)\n",
        "    list_morans_I.append(morans_I)\n",
        "    list_morans_p.append(morans_p)\n",
        "\n",
        "array_morans_I = np.array(list_morans_I)\n",
        "array_morans_p = np.array(list_morans_p)\n",
        "\n",
        "# Plotting the results\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(timepoints, array_morans_I, label=\"Moran's I\", color=\"blue\")\n",
        "plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
        "plt.title(\"Moran's I over Time\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Moran's I\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ziel: Berechnet die Pearson-Korrelation zwischen zwei Xarray-Daten (x und y), wobei dim='time' spezifiziert, dass die Korrelation entlang der Zeitdimension durchgeführt wird.\n",
        "\n",
        "xr.corr: Dies ist eine Funktion von Xarray, die den Pearson-Korrelationskoeffizienten zwischen zwei Variablen berechnet, indem sie ihre Werte entlang einer bestimmten Dimension (in diesem Fall time) vergleicht.\n",
        "\n",
        "x und y sind die beiden Xarray-Datenarrays (z. B. Zeitserien von sla und pressure_msl).\n",
        "dim='time' bedeutet, dass die Korrelation für jede räumliche Position über die Zeit hinweg berechnet wird. Zum Beispiel, wenn du Zeitserien für verschiedene geografische Punkte hast, wird der Korrelationswert für jeden Punkt berechnet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cartopy.crs as ccrs\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Select subset of data from start_time to end_time\n",
        "# start_time = \"2023-01-19\"\n",
        "# end_time = \"2023-10-21\"\n",
        "\n",
        "# Select all times in df_ocean where df_insitu[slev] larger then 1.0\n",
        "df_stormsurge = df_insitu[df_insitu[\"slev\"] > 1.0]\n",
        "# Select the timepoints from df_stormsurge\n",
        "timepoints = df_stormsurge[\"time\"].values\n",
        "\n",
        "ds_ocean_weather_interp_sub = ds_ocean_weather_interp.sel(time=timepoints)\n",
        "\n",
        "\n",
        "#time_string = f\"{start_time.strftime('%Y-%m-%d')} to {end_time.strftime('%Y-%m-%d')}\"\n",
        "time_string = f'Correlation of all timpoints if sturm surges'\n",
        "\n",
        "#ds_ocean_weather_interp_sub = ds_ocean_weather_interp.sel(time=slice(start_time, end_time))\n",
        "\n",
        "def pearson_r(x, y):\n",
        "    return xr.corr(x, y, dim='time')\n",
        "\n",
        "def plot_correlation(x, y, title=\"Correlation Map (Contour)\"):\n",
        "    \"\"\"\n",
        "    Plots the correlation map as a contour plot using Cartopy.\n",
        "    \n",
        "    Parameters:\n",
        "        x, y (xarray.DataArray): Variables to compute correlation from.\n",
        "        title (str): Title of the plot.\n",
        "    \"\"\"\n",
        "    correlation_map = pearson_r(x, y)\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 6))\n",
        "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "\n",
        "    # Konturplot\n",
        "    correlation_map.plot.contourf(\n",
        "        ax=ax,\n",
        "        transform=ccrs.PlateCarree(),\n",
        "        cmap='coolwarm', # \n",
        "        levels=50,  # Optional: Anzahl der Konturlinien\n",
        "        vmin=-1,\n",
        "        vmax=1,\n",
        "        cbar_kwargs={'label': 'Pearson Correlation Coefficient','orientation': 'horizontal', 'shrink': 0.8, 'pad': 0.05},\n",
        "\n",
        "    )\n",
        "\n",
        "    ax.coastlines()\n",
        "    ax.add_feature(cfeature.BORDERS)\n",
        "    # colors to land\n",
        "    ax.add_feature(cfeature.LAND, facecolor='lightgrey', alpha=0.9)\n",
        "    # add lat and lon gridlines\n",
        "    ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')\n",
        "    ax.set_title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Ignore RuntimeWarning\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "\n",
        "plot_correlation(ds_ocean_weather_interp_sub['sla'], ds_ocean_weather_interp_sub['pressure_msl'], title=f\"Correlation between SLA and Pressure from {time_string}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_correlation_with_currents(x, y, u, v, title=\"Correlation Map (Contour + Currents)\"):\n",
        "    \"\"\"\n",
        "    Plots the correlation map as a contour plot with ocean current arrows using Cartopy.\n",
        "\n",
        "    Parameters:\n",
        "        x, y (xarray.DataArray): Variables to compute correlation from.\n",
        "        u, v (xarray.DataArray): Zonal (uo) and meridional (vo) current components.\n",
        "        title (str): Title of the plot.\n",
        "    \"\"\"\n",
        "    correlation_map = pearson_r(x, y)\n",
        "\n",
        "    fig = plt.figure(figsize=(12, 6))\n",
        "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "\n",
        "    # Konturplot\n",
        "    correlation_map.plot.contourf(\n",
        "        ax=ax,\n",
        "        transform=ccrs.PlateCarree(),\n",
        "        cmap='coolwarm',\n",
        "        levels=21,\n",
        "        vmin=-1,\n",
        "        vmax=1,\n",
        "        cbar_kwargs={'label': 'Pearson Correlation Coefficient',\n",
        "                     'orientation': 'horizontal', 'shrink': 0.8, 'pad': 0.05},\n",
        "    )\n",
        "\n",
        "    # Subsampling für bessere Übersicht\n",
        "    step = 1\n",
        "    u_sub = u.isel(latitude=slice(None, None, step), longitude=slice(None, None, step))\n",
        "    v_sub = v.isel(latitude=slice(None, None, step), longitude=slice(None, None, step))\n",
        "\n",
        "    # Gitterkoordinaten extrahieren\n",
        "    lat_sub = u_sub.latitude.values\n",
        "    lon_sub = u_sub.longitude.values\n",
        "    lon2d, lat2d = np.meshgrid(lon_sub, lat_sub)\n",
        "\n",
        "    # Quiver-Pfeile plotten (auf 2D-Arrays achten!)\n",
        "    ax.quiver(\n",
        "        lon2d,\n",
        "        lat2d,\n",
        "        u_sub.values,\n",
        "        v_sub.values,\n",
        "        transform=ccrs.PlateCarree(),\n",
        "        scale=10,  # Anpassen nach Daten\n",
        "        width=0.002,\n",
        "        color='black'\n",
        "    )\n",
        "\n",
        "    # Zusätzliche Kartenfeatures\n",
        "    ax.coastlines()\n",
        "    ax.add_feature(cfeature.BORDERS)\n",
        "    ax.add_feature(cfeature.LAND, facecolor='lightgrey', alpha=0.9)\n",
        "    ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')\n",
        "    ax.set_title(title)\n",
        "    plt.show()\n",
        "\n",
        "u_mean = ds_ocean_weather_interp_sub['uo'].mean(dim='time')\n",
        "v_mean = ds_ocean_weather_interp_sub['vo'].mean(dim='time')\n",
        "\n",
        "\n",
        "plot_correlation_with_currents(\n",
        "    ds_ocean_weather_interp_sub['sla'],\n",
        "    ds_ocean_weather_interp_sub['pressure_msl'],\n",
        "    u_mean,\n",
        "    v_mean,\n",
        "    title=f\"Correlation between SLA and Pressure with Currents from {time_string}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import xarray as xr\n",
        "\n",
        "\n",
        "def select_nearest_valid_point(ds, variable_name, target_lat, target_lon):\n",
        "    \"\"\"\n",
        "    Wähle den nächstgelegenen gültigen Punkt (nicht-NaN) im Dataset für eine bestimmte Variable.\n",
        "    \n",
        "    Parameters:\n",
        "        ds (xr.Dataset): Das Eingabe-Dataset mit latitude, longitude, und time-Dimensionen.\n",
        "        variable_name (str): Name der Variable zur Prüfung auf Gültigkeit (z.B. 'wind_speed_10m').\n",
        "        target_lat (float): Ziel-Breitengrad.\n",
        "        target_lon (float): Ziel-Längengrad.\n",
        "\n",
        "    Returns:\n",
        "        xr.Dataset: Subset des ursprünglichen Datasets an der nächsten gültigen Position.\n",
        "        float: Breitengrad der gültigen Position.\n",
        "        float: Längengrad der gültigen Position.\n",
        "    \"\"\"\n",
        "    # Maske gültiger Punkte entlang der Zeitachse\n",
        "    valid_mask = ds[variable_name].notnull().any(dim='time')\n",
        "\n",
        "    # 2D-Gitter der Koordinaten\n",
        "    lat2d, lon2d = np.meshgrid(ds.latitude.values, ds.longitude.values, indexing='ij')\n",
        "\n",
        "    # Nur gültige Koordinaten extrahieren\n",
        "    valid_lat_points = lat2d[valid_mask.values]\n",
        "    valid_lon_points = lon2d[valid_mask.values]\n",
        "\n",
        "    # Distanzberechnung (euklidisch)\n",
        "    distances = np.sqrt((valid_lat_points - target_lat)**2 + (valid_lon_points - target_lon)**2)\n",
        "\n",
        "    # Index des nächsten gültigen Punkts\n",
        "    min_idx = np.argmin(distances)\n",
        "    nearest_lat = valid_lat_points[min_idx]\n",
        "    nearest_lon = valid_lon_points[min_idx]\n",
        "\n",
        "    print(f\"Nächstgelegener gültiger Punkt: lat={nearest_lat:.6f}, lon={nearest_lon:.6f}\")\n",
        "    \n",
        "    return ds.sel(latitude=nearest_lat, longitude=nearest_lon), nearest_lat, nearest_lon\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import xarray as xr\n",
        "from mpl_toolkits.basemap import Basemap\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# === 1. In-situ Daten laden ===\n",
        "# def load_insitu_data(filepath):\n",
        "#     ds = xr.open_dataset(filepath)\n",
        "#     df = ds.to_dataframe().reset_index()\n",
        "#     return df.rename(columns={\n",
        "#         \"TIME\": \"time\",\n",
        "#         \"SLEV\": \"slev\",\n",
        "#         \"LATITUDE\": \"latitude\",\n",
        "#         \"LONGITUDE\": \"longitude\"\n",
        "#     })\n",
        "\n",
        "df_insitu = load_insitu_data()\n",
        "df_insitu = flensburg_data_processing(df_insitu)\n",
        "df_insitu = interpolate_missing_times(df_insitu)\n",
        "\n",
        "insitu_location = (df_insitu.latitude.iloc[0], df_insitu.longitude.iloc[0])\n",
        "\n",
        "# Get the nearest valid point in xarray to Flensburg\n",
        "target_lat = 54.5\n",
        "target_lon = 10.0\n",
        "flensburg_ds, nearest_lat, nearest_lon = select_nearest_valid_point(ds_ocean_weather_interp_sub, 'wind_speed_10m', target_lat, target_lon)\n",
        "\n",
        "\n",
        "\n",
        "# === 2. Wetterdaten vorbereiten ===\n",
        "# Stelle sicher, dass flensburg_ds vorher korrekt definiert ist\n",
        "wetter_df = flensburg_ds.to_dataframe().reset_index().set_index(\"time\")\n",
        "wetter_location = (wetter_df.latitude.iloc[0], wetter_df.longitude.iloc[0])\n",
        "\n",
        "\n",
        "# === 3. Karte mit Basemap zeichnen ===\n",
        "def plot_locations(insitu_loc, weather_loc):\n",
        "    center_lat = (insitu_loc[0] + weather_loc[0]) / 2\n",
        "    center_lon = (insitu_loc[1] + weather_loc[1]) / 2\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    m = Basemap(projection='merc',\n",
        "                llcrnrlat=center_lat - 2, urcrnrlat=center_lat + 2,\n",
        "                llcrnrlon=center_lon - 2, urcrnrlon=center_lon + 2,\n",
        "                resolution='i')\n",
        "\n",
        "    m.drawcoastlines()\n",
        "    m.drawcountries()\n",
        "    m.drawmapboundary(fill_color='white')\n",
        "    m.fillcontinents(color='lightgray', lake_color='white')\n",
        "    m.drawparallels(np.arange(0., 90., 0.5), labels=[1,0,0,0])\n",
        "    m.drawmeridians(np.arange(0., 180., 0.5), labels=[0,0,0,1])\n",
        "\n",
        "    x_insitu, y_insitu = m(insitu_loc[1], insitu_loc[0])\n",
        "    x_weather, y_weather = m(weather_loc[1], weather_loc[0])\n",
        "\n",
        "    m.plot(x_insitu, y_insitu, 'bo', markersize=8, label='In-situ Location')\n",
        "    m.plot(x_weather, y_weather, 'ro', markersize=8, label='Weather Location')\n",
        "\n",
        "    plt.text(x_insitu+10000, y_insitu+10000, 'Flensburg In-Situ', fontsize=12, color='black')\n",
        "    plt.text(x_weather+10000, y_weather+10000, 'Closest Point', fontsize=12, color='red')\n",
        "\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.title('In-situ vs. Wetterpunkt')\n",
        "    plt.show()\n",
        "\n",
        "plot_locations(insitu_location, wetter_location)\n",
        "\n",
        "# === 4. Zeitliche Synchronisierung ===\n",
        "df_insitu = df_insitu.set_index(\"time\").resample(\"h\").mean(numeric_only=True)\n",
        "wetter_df = wetter_df.resample(\"h\").mean()\n",
        "\n",
        "# === 5. Daten zusammenführen ===\n",
        "merged_df = pd.merge(df_insitu, wetter_df, left_index=True, right_index=True, how=\"inner\")\n",
        "display(merged_df.head(2))\n",
        "display(merged_df.tail(2))\n",
        "\n",
        "# === 6. Explorative Analyse ===\n",
        "features = ['sla', 'slev', 'wind_speed_10m', 'surface_pressure', 'precipitation', 'wind_direction_10m', 'vo']\n",
        "#features = merged_df.columns.tolist()\n",
        "\n",
        "\n",
        "sns.pairplot(merged_df[features], diag_kind='kde')\n",
        "plt.show()\n",
        "\n",
        "# === 7. Korrelationen anzeigen ===\n",
        "correlation = merged_df.corr(numeric_only=True)\n",
        "print(\"Korrelationsmatrix:\")\n",
        "display(correlation[\"slev\"].sort_values(ascending=False))\n",
        "\n",
        "# 10 grö0te Korrelationen\n",
        "features = correlation[\"slev\"].sort_values(ascending=False).nlargest(10).index.tolist()\n",
        "features += correlation[\"slev\"].sort_values(ascending=False).nsmallest(10).index.tolist()\n",
        "print(features)\n",
        "\n",
        "# === 8. Zeitreihenvisualisierung ===\n",
        "merged_df[features].plot(\n",
        "    subplots=True, figsize=(10, 17), title=f\"Zeitreihen from {time_string}\")\n",
        "plt.tight_layout()\n",
        "plt.legend(loc='upper left')\n",
        "plt.xlabel(\"Time\")\n",
        "plt.show()\n",
        "\n",
        "# === 9. Lineare Regression ===\n",
        "def run_regression(df, target_col, feature_cols):\n",
        "    X = df[feature_cols]\n",
        "    y = df[target_col]\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    #X_scaled = X\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_scaled, y)\n",
        "\n",
        "    print(\"\\nRegressionskoeffizienten:\")\n",
        "    for feat, coef in zip(feature_cols, model.coef_):\n",
        "        print(f\"{feat}: {coef:.4f}\")\n",
        "    print(f\"R² Score: {model.score(X_scaled, y):.4f}\")\n",
        "\n",
        "run_regression(merged_df, \"slev\", features[1:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_merged_sub_sub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_scatter(ds_merged, x_col, y_col, c, title, xlabel, ylabel, dim=['latitude', 'longitude']):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(ds_merged[x_col].mean(dim=dim), ds_merged[y_col].mean(dim=dim), c=ds_merged[c].mean(dim=dim), cmap='viridis', alpha=0.5)\n",
        "    plt.colorbar(label=c)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.show()\n",
        "\n",
        "plot_scatter(ds_merged=ds_merged_sub, \n",
        "             x_col='wind_speed_10m', \n",
        "             y_col='sla',\n",
        "             c='sla',\n",
        "            title='SLA vs Pressure MSL',\n",
        "            xlabel='SLA [m]',\n",
        "            ylabel='sla',\n",
        "            )\n",
        "\n",
        "\n",
        "# col1 = ds_merged['sla'].mean(dim=['latitude', 'longitude'])\n",
        "# col2 = ds_merged['wind_speed_10m'].mean(dim=['latitude', 'longitude'])\n",
        "\n",
        "# plt.scatter(col1, col2, alpha=0.5, marker='o', cmap='viridis', c=ds_merged['wind_direction_10m'].mean(dim=['latitude', 'longitude']))\n",
        "# plt.xlabel('mean SLA [m]')\n",
        "# plt.ylabel('mean Wind Speed [m/s]')\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "\n",
        "\n",
        "def plot_contour(ds_merged, x_col, y_col, c, title, xlabel, ylabel, bins=500, dim=['latitude', 'longitude']):\n",
        "    \"\"\"\n",
        "    Erzeugt einen Contourplot von Mittelwerten über angegebene Dimensionen (z. B. lat/lon).\n",
        "    \"\"\"\n",
        "    # Mittelwerte über Raumdimensionen\n",
        "    x = ds_merged[x_col].mean(dim=dim).values.flatten()\n",
        "    y = ds_merged[y_col].mean(dim=dim).values.flatten()\n",
        "    z = ds_merged[c].mean(dim=dim).values.flatten()\n",
        "\n",
        "    # Entferne NaNs\n",
        "    mask = ~np.isnan(x) & ~np.isnan(y) & ~np.isnan(z)\n",
        "    x, y, z = x[mask], y[mask], z[mask]\n",
        "\n",
        "    # Erzeuge ein 2D-Gitter durch Histogramm-Binning\n",
        "    xi = np.linspace(np.min(x), np.max(x), bins)\n",
        "    yi = np.linspace(np.min(y), np.max(y), bins)\n",
        "    Xi, Yi = np.meshgrid(xi, yi)\n",
        "\n",
        "    # Interpolation der Z-Werte auf das Gitter\n",
        "    from scipy.interpolate import griddata\n",
        "    Zi = griddata((x, y), z, (Xi, Yi), method='linear')\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    contour = plt.contourf(Xi, Yi, Zi, levels=50, cmap='viridis')\n",
        "    cbar = plt.colorbar(contour)\n",
        "    cbar.set_label(c)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_contour(ds_merged=ds_merged, \n",
        "             x_col='wind_speed_10m', \n",
        "             y_col='wind_direction_10m',\n",
        "             c='sla',\n",
        "             title='Contourplot: SLA vs Pressure MSL',\n",
        "             xlabel='SLA [m]',\n",
        "             ylabel='Pressure MSL [hPa]',\n",
        "             bins=100,\n",
        "            )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_interp = ds_weather.interpolate_na(dim=\"latitude\", method=\"linear\")\n",
        "ds_interp = ds_interp.interpolate_na(dim=\"longitude\", method=\"linear\")\n",
        "ds_interp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Altes Gitter\n",
        "old_lats = ds_interp.latitude\n",
        "old_lons = ds_interp.longitude\n",
        "\n",
        "# Neues feineres Gitter erzeugen (z. B. 0.25° statt 1.0° Auflösung)\n",
        "new_lats = np.arange(old_lats.min(), old_lats.max(), 0.25)\n",
        "new_lons = np.arange(old_lons.min(), old_lons.max(), 0.25)\n",
        "\n",
        "# Interpolation\n",
        "ds_interp = ds_interp.interp(latitude=new_lats, longitude=new_lons, method='linear')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_interp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Beispiel: Temperatur auswählen\n",
        "temperature = ds_interp['pressure_msl'].sel(time='2023-10-18T12:00:00')\n",
        "\n",
        "# Plot\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "ax = plt.axes(projection=ccrs.PlateCarree())  # oder z. B. ccrs.Mercator()\n",
        "\n",
        "temperature.plot(ax=ax, transform=ccrs.PlateCarree(), cmap='coolwarm', cbar_kwargs={'label': '°C'})\n",
        "\n",
        "# Extras: Küstenlinien etc.\n",
        "ax.coastlines()\n",
        "ax.add_feature(cfeature.BORDERS)\n",
        "ax.set_title(\"Temperaturkarte\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temperature = ds_interp['pressure_msl'].sel(time='2023-10-18T12:00:00')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6), subplot_kw={'projection': ccrs.PlateCarree()})\n",
        "ax.coastlines()\n",
        "ax.add_feature(cfeature.BORDERS)\n",
        "\n",
        "# Konturlinien\n",
        "cs = ax.contourf(temperature.longitude, temperature.latitude, temperature, \n",
        "                 levels=20, cmap='coolwarm',  # <- Korrektur hier\n",
        "                 linewidths=1, transform=ccrs.PlateCarree())\n",
        "\n",
        "\n",
        "ax.set_title(\"Konturlinien des Luftdrucks\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_interp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "u = ds_interp['u10'].sel(time='2023-10-18T12:00:00')  # Ost-Komponente\n",
        "v = ds_interp['v10'].sel(time='2023-10-18T12:00:00')  # Nord-Komponente\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6), subplot_kw={'projection': ccrs.PlateCarree()})\n",
        "ax.coastlines()\n",
        "ax.add_feature(cfeature.BORDERS)\n",
        "\n",
        "# Vektorpfeile (Wind)\n",
        "q = ax.quiver(u.lon[::5], u.lat[::5], u[::5, ::5], v[::5, ::5], transform=ccrs.PlateCarree(), scale=700)\n",
        "\n",
        "ax.set_title(\"Windvektoren\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 6), subplot_kw={'projection': ccrs.PlateCarree()})\n",
        "ax.coastlines()\n",
        "\n",
        "ax.streamplot(u.lon, u.lat, u.values, v.values, transform=ccrs.PlateCarree(), color='blue', density=1.5)\n",
        "ax.set_title(\"Stromlinien der Windrichtung\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp = ds_interp['temperature_2m'].mean(dim=['latitude', 'longitude'])\n",
        "humidity = ds_interp['relative_humidity_2m'].mean(dim=['latitude', 'longitude'])\n",
        "\n",
        "plt.scatter(temp, humidity, alpha=0.5)\n",
        "plt.xlabel('Temperatur [°C]')\n",
        "plt.ylabel('relative Luftfeuchtigkeit [%]')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "\n",
        "# Beispielzeitpunkt auswählen\n",
        "time_sel = '2023-10-20T12:00'\n",
        "\n",
        "# Daten selektieren\n",
        "temp = ds_interp['relative_humidity_2m'].sel(time=time_sel)\n",
        "wind_speed = ds_interp['wind_speed_10m'].sel(time=time_sel)\n",
        "wind_dir = ds_interp['wind_direction_10m'].sel(time=time_sel)\n",
        "\n",
        "# Windrichtung und -geschwindigkeit → u, v-Komponenten umrechnen\n",
        "wind_u = wind_speed * -np.sin(np.deg2rad(wind_dir))\n",
        "wind_v = wind_speed * -np.cos(np.deg2rad(wind_dir))\n",
        "\n",
        "# Plot erstellen\n",
        "fig, ax = plt.subplots(figsize=(12, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
        "\n",
        "# Temperaturkarte (colormap)\n",
        "temp.plot(ax=ax, transform=ccrs.PlateCarree(), cmap='coolwarm', cbar_kwargs={'label': 'Temperatur [°C]'})\n",
        "\n",
        "# Küstenlinie, Ländergrenzen etc.\n",
        "ax.coastlines()\n",
        "ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
        "ax.add_feature(cfeature.LAND, facecolor='lightgray', alpha=0.3)\n",
        "\n",
        "# Windvektoren\n",
        "# Downsamplen für bessere Übersicht (z. B. jeden 3. Punkt)\n",
        "step = 2\n",
        "lat = ds_interp.latitude[::step]\n",
        "lon = ds_interp.longitude[::step]\n",
        "u = wind_u[::step, ::step]\n",
        "v = wind_v[::step, ::step]\n",
        "\n",
        "ax.quiver(lon, lat, u, v, transform=ccrs.PlateCarree(), color='black', scale=700)\n",
        "\n",
        "# Titel\n",
        "ax.set_title(f\"Temperatur und Wind am {time_sel}\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Merge Dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def process_coord(df: pd.DataFrame, coord: tuple) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Processes a subset of the DataFrame for a given coordinate.\n",
        "    \"\"\"\n",
        "    df_sub = df[df['position'] == coord].copy()\n",
        "    df_sub.drop(columns=['latitude', 'longitude', 'position'], inplace=True)\n",
        "\n",
        "    value_columns = df_sub.columns.difference(['time'])\n",
        "    df_sub.rename(\n",
        "        columns={col: f\"{col}_{coord}\" for col in value_columns},\n",
        "        inplace=True\n",
        "    )\n",
        "\n",
        "    return df_sub\n",
        "\n",
        "def convert_df_joblib(df: pd.DataFrame, n_jobs: int = -1) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Converts the DataFrame by pivoting values for unique coordinates\n",
        "    using parallel processing via joblib.\n",
        "    \"\"\"\n",
        "    df['position'] = list(zip(df['latitude'], df['longitude']))\n",
        "    unique_coords = df['position'].unique()\n",
        "    print(f\"Number of unique coordinates: {len(unique_coords)}\")\n",
        "\n",
        "    df_merged = pd.DataFrame({'time': df['time'].unique()})\n",
        "\n",
        "    # Parallel processing\n",
        "    results = Parallel(n_jobs=n_jobs)(\n",
        "        delayed(process_coord)(df, coord) for coord in tqdm(unique_coords)\n",
        "    )\n",
        "\n",
        "    # Merge all partial DataFrames\n",
        "    for df_sub in results:\n",
        "        df_merged = df_merged.merge(df_sub, on='time', how='left')\n",
        "\n",
        "    return df_merged\n",
        "\n",
        "# Usage\n",
        "df_ocean_converted = convert_df_joblib(df_ocean)\n",
        "df_weather_converted = convert_df_joblib(df_weather)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge df_ocean and df_weather and df_insitu\n",
        "df_merged = df_ocean_converted.merge(df_weather_converted, on='time', how='inner')\n",
        "df_merged = df_merged.merge(df_insitu, on='time', how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_merged.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_merged.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# correlation matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "corr = df_merged.corr()\n",
        "# mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "# sns.heatmap(corr, mask=mask, cmap=\"coolwarm\", annot=False, fmt=\".2f\", square=True, cbar_kws={\"shrink\": .8})\n",
        "# plt.title(\"Correlation Matrix\")\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find the highest correlation between the columns and slev\n",
        "corr_slev = corr[\"slev\"].nlargest(100)\n",
        "\n",
        "\n",
        "# Display the correlation values in a bar plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x=corr_slev.index, y=corr_slev.values)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Correlation with slev\")\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"Correlation\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_slev.index "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find the highest correlation between the columns and slev\n",
        "corr_slev = corr[\"slev\"].nsmallest(100)\n",
        "\n",
        "\n",
        "# Display the correlation values in a bar plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x=corr_slev.index, y=corr_slev.values)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Correlation with slev\")\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"Correlation\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_index_name(corr_slev: pd.Series, name: str) -> str:\n",
        "    \"\"\"\n",
        "    Get the first index name that contains the specified substring.\n",
        "    \"\"\"\n",
        "    for col in corr_slev.index:\n",
        "        if name in col:\n",
        "            return col\n",
        "    return None\n",
        "\n",
        "# Get the index name of the column that contains 'wind'\n",
        "sla_col = get_index_name(corr_slev, \"sla\")\n",
        "wo_col = get_index_name(corr_slev, \"wo\")\n",
        "pressure_msl_col = get_index_name(corr_slev, \"pressure_msl\")\n",
        "surface_pressure_col = get_index_name(corr_slev, \"surface_pressure\")\n",
        "print(f\"Wind column: {sla_col}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def scale_df(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Scale the DataFrame using MinMaxScaler, excluding the 'time' column.\n",
        "    \"\"\"\n",
        "    scaler = MinMaxScaler()\n",
        "    \n",
        "    # Save time column and drop it from the data to be scaled\n",
        "    time = df[\"time\"]\n",
        "    data_to_scale = df.drop(columns=[\"time\"])\n",
        "\n",
        "    # Fit and transform the data (excluding 'time')\n",
        "    scaled_values = scaler.fit_transform(data_to_scale)\n",
        "\n",
        "    # Create scaled DataFrame\n",
        "    df_scaled = pd.DataFrame(scaled_values, columns=data_to_scale.columns)\n",
        "    df_scaled[\"time\"] = time\n",
        "\n",
        "    return df_scaled\n",
        "\n",
        "# Beispiel-Nutzung\n",
        "df_scaled = scale_df(df_merged)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_position_of_column(df: pd.DataFrame, col_name: str) -> tuple:\n",
        "    \"\"\"\n",
        "    Get the position (latitude, longitude) of a specific column in the DataFrame.\n",
        "    \"\"\"\n",
        "    # Split the column name to extract latitude and longitude\n",
        "    parts = col_name.split(\"_\")[-1]\n",
        "    parts = eval(parts)\n",
        "    lat = float(parts[-2])\n",
        "    lon = float(parts[-1])\n",
        "    return lat, lon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pressure_msl_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot slev\n",
        "\n",
        "# normalize the like MinMaxScaler\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Plot the water level\n",
        "ax.plot(df_scaled['time'], df_scaled['slev'], label='Wasserstand', color='blue')\n",
        "\n",
        "# plot the sla_col \n",
        "#ax.plot(df_scaled['time'], df_scaled[sla_col], label=sla_col, color='red')\n",
        "\n",
        "ax.plot(df_scaled['time'], df_scaled[wo_col], label=wo_col, color='green')\n",
        "\n",
        "#ax.plot(df_scaled['time'], df_scaled[pressure_msl_col], label=pressure_msl_col, color='orange')\n",
        "\n",
        "\n",
        "# plot the position of the column on map\n",
        "lat, lon = get_position_of_column(df_scaled, wo_col)\n",
        "print(f\"Position of {wo_col}: {lat}, {lon}\")\n",
        "# Create a Basemap\n",
        "fig_map, ax_map = plt.subplots(figsize=(12, 10))\n",
        "m = Basemap(\n",
        "    projection=\"cyl\",\n",
        "    resolution=\"i\",\n",
        "    llcrnrlon=lon_grid.min(),\n",
        "    urcrnrlon=lon_grid.max(),\n",
        "    llcrnrlat=lat_grid.min(),\n",
        "    urcrnrlat=lat_grid.max(),\n",
        "    ax=ax_map,\n",
        ")\n",
        "# Draw map features\n",
        "m.drawcoastlines()\n",
        "m.drawcountries()\n",
        "m.fillcontinents(color=\"0.8\")\n",
        "m.drawstates()\n",
        "m.drawmapboundary(fill_color=\"aqua\")\n",
        "m.fillcontinents(color=\"coral\", lake_color=\"aqua\", alpha=0.2)\n",
        "# Scatterplot for ocean data\n",
        "x, y = m(lon, lat)\n",
        "m.scatter(x, y, color=\"blue\", label=\"Ocean Data\", zorder=5)\n",
        "# Add a title and legend\n",
        "plt.title(f\"Position of {pressure_msl_col} on map\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "040eea0881a04d02b7faf2c3effca4d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12379b91f43d477fa27170daddeb9369": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1383b02a5f4049a080c3ca2c325c6687": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26543bcb1f034139ba024498bdd39439",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b84f47ad66d44767a8a978fd8a585aef",
            "value": 2
          }
        },
        "158843476d7541beb3067ca7127de1a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24f5d3de61ae4482b3c8b8e0a48351aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26543bcb1f034139ba024498bdd39439": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f5357c36f444952bd174a0619bda09b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_849c76b486d5441b89ce28d3cd1411a1",
            "placeholder": "​",
            "style": "IPY_MODEL_706206b9195947ef9ea01b859a75d8fb",
            "value": " 2/2 [00:00&lt;00:00,  5.50it/s]"
          }
        },
        "506b51b02f264362a837c7b63b2fa16e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "517d5f66cd154580adc0d63ced53717a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f6c7fd47c6f408db604aa37bc3bb611": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24f5d3de61ae4482b3c8b8e0a48351aa",
            "max": 330,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_040eea0881a04d02b7faf2c3effca4d9",
            "value": 330
          }
        },
        "634e039630b242f9b35a47045a1b8d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd3fad87eec54068822b0721e58e9796",
              "IPY_MODEL_5f6c7fd47c6f408db604aa37bc3bb611",
              "IPY_MODEL_efbe98b509c444509d33745aa79036c0"
            ],
            "layout": "IPY_MODEL_703f229377d14f6e999cb2ab8e6e3de6"
          }
        },
        "703f229377d14f6e999cb2ab8e6e3de6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "706206b9195947ef9ea01b859a75d8fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "849c76b486d5441b89ce28d3cd1411a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94097d8ac96d4258af721da99d479a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc90ebde1df94b8e921938d6146e2617",
              "IPY_MODEL_1383b02a5f4049a080c3ca2c325c6687",
              "IPY_MODEL_2f5357c36f444952bd174a0619bda09b"
            ],
            "layout": "IPY_MODEL_506b51b02f264362a837c7b63b2fa16e"
          }
        },
        "b84f47ad66d44767a8a978fd8a585aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba21969bab124b4e89111d677f64de17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c52f4a116ac0475792786df43391da31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd3fad87eec54068822b0721e58e9796": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12379b91f43d477fa27170daddeb9369",
            "placeholder": "​",
            "style": "IPY_MODEL_c52f4a116ac0475792786df43391da31",
            "value": "100%"
          }
        },
        "dc90ebde1df94b8e921938d6146e2617": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_158843476d7541beb3067ca7127de1a0",
            "placeholder": "​",
            "style": "IPY_MODEL_ba21969bab124b4e89111d677f64de17",
            "value": "100%"
          }
        },
        "efbe98b509c444509d33745aa79036c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_517d5f66cd154580adc0d63ced53717a",
            "placeholder": "​",
            "style": "IPY_MODEL_fa084275366141008eebae1bb628e9cb",
            "value": " 330/330 [00:20&lt;00:00, 18.45it/s]"
          }
        },
        "fa084275366141008eebae1bb628e9cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
